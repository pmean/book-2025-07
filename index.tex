% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother





\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={jump-start-book, last major update 2025-09-10},
  pdfauthor={Steve Simon},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{jump-start-book, last major update 2025-09-10}
\author{Steve Simon}
\date{2023-10-03}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

While this book is in progress, I will use the section of the preface to
track my activity (or lack of activity). When the book is complete, the
first section drops and I revert to a normal preface.

On \textbf{2025-12-15}, I continued work on Chapter 18 (How to write a
literature review). I have the first three sections laid out nicely, but
I still have to talk about the ``fly in the ointment'' (too many/too few
references). The count for the entire book is up to 22 thousand words.

On \textbf{2025-12-12}, I started work on Chapter 18 (How to write a
literature review). This is going to be one of the hardest chapters to
write--partly because the topic is so diffuse and partly because there
is so much to summarize. I got a nice introduction, revised some of the
section headings and got a bit of material in the first and second
section headings. I now have 21 thousand words.

On \textbf{2025-10-10}, I continued work on Chapter 9. I have a pretty
complete narrative for section 9.1. I now have about 14 thousand words
total, with four relatively complete chapters and four partially
completed chapters.

On \textbf{2025-10-03}, I started work on Chapter 9, Setting up a data
entry process. I added ten internal and five external references and a
few introductory paragraphs. I now have about 13 thousand words total,
with four relatively complete chapters and now four partially completed
chapters.

On \textbf{2025-09-10}, I standardized the bibliographies at the end of
each chapter.

On \textbf{2025-09-05}, I moved text that was wrongly placed in chapter
20 back in the correct chapter (19). I started work on chapter 21, but
there is a lot left to be written. I began organizing my bibliography
better. I now have about 11 thousand words total, with four relatively
complete chapters and now three partially completed chapters.

On \textbf{2025-08-29}, I completed a pretty good draft of chapter 19,
writing a methods section. This adds to three other chapters that we
already in good form (chapters 1, 5, and 11). There is also a very
little bit written for chapters 2 and 3. The total word count is just
around 10 thousand, which is a jump from 7 thousand that the book had
been stuck at for many months.

\textbf{The real preface starts here}

This book was a long time coming. I had just finished a book Statistical
Evidence in Medical Trials in 2006, and had a nice idea for a second
book (this one that you are holding right now). It was more or less
written, spread across a few dozen web pages that I had written over the
past eight years. Surely, it would drop right into my lap.

Well, it was just like the John Lennon lyric in ``Beautiful Boy'' about
how life is what happens while you're making other plans. Actually, that
makes it sound like I had a bunch of unexpected (and maybe tragic)
things happed over the past couple of decades. It is actually simpler
than that. There's a computer term, thrashing, that refers to a
multi-tasking computer that spends more time switching from task to task
than in getting any of the tasks done. That's the verb that best
describes my life. I'm thrashing.

Every year I'd show up at the Joint Statistics Meeting and look for the
Cambridge University Press booth. I'd say hello, usually to Lauren
Cowles, sometimes to another representative. This is the year, I'd tell
them, that I'll get the book written. I know exactly what I need to do.
And every year, I'd write a lot less than I intended to. Too much
thrashing.

I turned a corner (slowly) in 2023 when I converted my thin writings
into a book project in Quarto. I really love Quarto and if you have been
using RMarkdown for a while, you should really switch. It's an easy
transition, and everything is so much more intuitive under Quarto.

\textbf{When I really do complete the book, I will add:}

So I'm finally done. It was a long time coming, but it's here. Read on!

\bookmarksetup{startatroot}

\chapter{Introduction}\label{introduction}

This is a great book. Some of the material here is reproduced from my
\href{http://www.pmean.com/10/SecondBook.html}{original book proposal},
published in 2010-07-23.

Refer to the \href{http://www.pmean.com/10/Contents.html}{tentative
table of contents}, published 2010-07-24.

This book will explain the next three steps that you have to take at any
stage of your research project and it is targeted to beginning
researchers who are often confused about the research process and are
often unsure about what to do next.

When people come into my office asking for advice about Statistics, they
may be at the beginning, the planning phase of the study. Or they may be
getting their data ready for data analysis. Or they may be figuring out
which data analysis they are supposed to be using. Or they may be
thinking about how to write up all the results. The one thing in common
is that they come to see me when they are ``stuck.'' There are a few
exceptions, people who know what they want to do next and they just want
to run their thoughts by me to get my opinion. But most people, if they
knew what they were supposed to be doing, they'd be doing those things.

So what do I advise people to do when they are stuck? I can't lay out
the entire task in front of them, but I can almost always tell them what
the next few steps should be. If they take their first three steps
carefully, the following steps should eventually become obvious.

I am writing this book to reach people who can't visit me in person.
This book is for you if you have to struggle with a research project,
especially your first major research project, and you want guidance on
how to best proceed. The examples I give will be targeted to a medical
research setting and to studies involving humans, but should be broadly
applicable to other research areas, especially research in the social
sciences.

There's a certain amount of arrogance in writing a book and expecting
people to pay good money to read it. I'm certainly arrogant enough, but
I hope this book will justify that arrogance. I do have more than 25
years of consulting experience in academic settings, in the federal
government, in a hospital, and as an independent consultant. The one
advantage of being old is that I've seen it all before. I could not have
written this book twenty or even ten years ago.

There's a second level of arrogance, though, in presupposing that I can
offer advice to you without ever having met you and without knowing
anything about your research project. There are certainly some research
projects where the steps I suggest may not make sense, and I apologize
in advance to anyone who has such a project and does not get any benefit
from this book. I do believe, however, that there is a commonality in
most research. In particular, while the final steps in a data analysis
might be impossible to predict, the initial steps can be largely
predicted, based on my experience. And that's what most people need.
Once they get some momentum back in their research project, they usually
find a way to finish things up.

The general advice behind the steps I am suggesting is that you should
never dive into the deep end of the swimming pool first. There's a
natural tendency to tackle the hardest thing first, but this is a
mistake. Instead, wade in gently at the shallow end. Thus, the first
step for a descriptive data analysis is ``know your count'' which means
to know how many observations are in your data set and how many values
are missing in each of your key variables. This sounds like a trivial
step, but you must do this. If you don't know how much data you have,
then you will be likely to overlook important details later on like how
complex of a statistical model might be supported by your data set.

This is not just advice that I offer to you, but advice I follow myself.
When I help out with a new research problem or a new data set, I can't
jump in the deep end either. I need to get comfortable with things.
Small easy steps will help build my confidence before I tackle the big
things.

This book covers the full range of research. The first few chapters talk
about the steps you need to take in designing your research study. A
good research plan, put in writing, is essential for quality research.
No one asks me about how to collect the data, but once they have it,
they need to know how to enter it into the computer, if it is on paper,
or how to import the data into a software package if it comes from an
electronic source.

Once you have data in a program like SPSS, you may not know what
procedures to use. I have chapters on how to start up a descriptive data
analysis (the foundation of all other data analyses), and how to begin
more complex data analyses like linear regression, logistic regression,
and survival data analysis. I use SPSS in my examples for these chapters
because I think it is an ideal statistical package for beginners,
because it is widely available in many academic and medical centers, and
it is easy to explain. But the general principles apply if you are using
SAS, STATA, or any other statistical package.

Finally, once you have all your data analysis, you need to start writing
up your results. I have chapters on how to write the methods section,
results section, and discussion section of a typical research paper.

I can't talk about purely scientific issues. If you're stuck because you
can't get your flow cytometer to work, you won't find any help here.
There is, of course, substantial overlap between science and statistics,
so I won't shy away from talking about this entirely. Just keep in mind
that my comments regarding science are as an outsider and that I do not
have any special expertise except for what little that has rubbed off on
me from the very intelligent scientists and doctors that I have
collaborated with.

There are book out there that offer a more comprehensive overview of
each of these steps. If you are writing a questionnaire, for example,
Alreck and Settle offer complete and thorough advice on what to do.
There are a wide range of books about how to run SPSS, and Julie Pallant
has an excellent one for beginners. If you are interested in what
statistical tests to use when, then Norman and Streiner have an
entertaining and informative book. If you are writing up results for
publication, then look no further than Lang and Secic, a definitive
guide with examples from the published literature and comprehensive
checklists of all the things you need.

What's different about my book is that I am not trying to be a
comprehensive guide that explains every single step that you might
possibly take. Those guides are important but they are also difficult to
read when your concern is not with every single step of the process but
rather in deciding what you should be doing right now.

Each chapter starts with an introduction and then defines the first
three steps that you should take at this stage. Finally, I list some
special cases that can cause special difficulties (the fly in the
ointment) and which might require a more intense interaction with your
statistical consultant.

I do need to place some important limitations. Otherwise, this book
would be impossibly long. I am going to focus on clincial research:
research that focusses directly on the health care of human patients.
Much of the material in this book will still be relevant if you are
working with animals, either for veterinary care or as a mdoel for
testing before testing in humans. But I don't want to talk about how you
obtain human patients in one paragraph and then switch to how you obtain
animal patients in the next paragraph. Likewise, I am going to bypass
some of the special considerations for in vitro studies.

I also do not have the luxury of discussing studies outside of medicine.
If your research involves education, marketing, or political science,
half of the things I discuss will be relevant, but there will also be
special considerations that I cannot address. I'd love to do so, because
these are all such fun and interesting areas of research. But space is
limited and I should focus on the clinical side because that is where
most of my experience is.

\section{Bibliography}\label{bibliography}

Alreck and Settle

Lang and Secic

Norman and Streiner

Fear is often a paralyzing emotion, and it may be just fear itself that
is causing your difficulties. Research is not easy, but don't fool
yourself into thinking that it is beyond your capabilities. You have to
be a very smart person to be in a position where you are capable of
doing an independent research project, so you are more capable than you
might believe. You can get your research project started, and if it is
stalled, you can get a jumpstart that will help you get moving again.
Just focus on what your next three steps should be.

\bookmarksetup{startatroot}

\chapter{Picking a research topic}\label{picking-a-research-topic}

This chapter is based on an email from Ronan Conroy to a statistics
listserv that was
\href{http://new.pmean.com/steps-in-developing-research-ideas/}{reproduced}
on my website.

For some people, picking a research topic is easy. Your boss will tell
you what to work on. For a few jobs, you have enough independence that
you get to choose, but even in those settings, the nature of the company
that you work for will determine what the best research topics are.

The people who have problems picking a research topics are students.
They have to find something suitable for a thesis or dissertation, but
they have never done any serious research before. Where to start, where
to start?

The others who have problems picking a research topic are people working
in a setting that is primarily clinical. The day-to-day demands keep you
busy enough. Even so, you want to do some research, but there is not a
lot of guidance from above. Where to start, where to start?

\section{Step 1. Describe what bothers
you}\label{step-1.-describe-what-bothers-you}

Over many decades, I have learned that irritation is the germ for many
research ideas. it's like that annoying little grain of sand inside an
oyster that turns into a pearl.

So what irritates you? It is either something that you are currently
doing in your job that makes a difference, but no one else is following
your lead. What is wrong with those people? It's obvious to me how
things should be done.

You are not in a position to impose your will on others, so you have to
persuade them. And half of the people you have to persuade are smarter
than you. The other half thinks they are smarter than you.

What will convince such a stubborn group? Well, remember the famous
quote from W. Edwards Deming, ``In God we trust, all others must bring
data.'' He also said, ``Without data, you are just another person with
an opinion.''

Perhaps the best illustration of the importance of data comes from the
Crimean War. Florence Nightingale, the founder of modern nursing. She
toiled in a military hospital caring for wounded soldiers. The death
rates at this hospital were horrific, and most deaths came not from the
battle wounds, but rather from illnesses caught during recuperation.
Through careful sanitation, better nutrition, and other reforms, she
greatly reduced the number of hospital deaths.

Florence Nightingale wanted to see these changes implemented in other
hospitals, getting attention from the authorities, especially for a
woman, was difficult. She devoted herself to collecting statistics,
seeing those as the key to persuasion. And it worked. Her testimony
before various commisions and politicians led to the codification of
many of her reforms.

So if you are doing something that can change the world, get the world
to change by collecting some data.

The flip side of the irritation coin is when you yourself are doing
something that you know isn't working and you'd like to fix it. Think
about what you might change. But don't just change right away. Develop a
plan.

\section{Bibliography}\label{bibliography-1}

Conroy R. Where do research ideas come from? PMean blog, 1999-09-20.
Available in
\href{http://pmean.com/posts/steps-in-developing-research-ideas/}{html
format}.

\bookmarksetup{startatroot}

\chapter{Selecting your research
hypothesis}\label{selecting-your-research-hypothesis}

This chapter is based on a webpage I wrote in 1999.

\section{Step 1. Choose an outcome
measure}\label{step-1.-choose-an-outcome-measure}

Do you know, in a quantitative sense, how bad things are right now? If
not, plan how you are going to measure yourself. In other words, define
an outcome measure. Think about what other aspects of your patient care
might be affected by the change and measure them also.

Then think about how you are going to measure the effects of your
change. This is important. Sometimes you change things for the better,
but sometimes your changes have no impact. It's even possible that your
changes could make things worse instead of better.

\section{Step 2. Define your patient
population}\label{step-2.-define-your-patient-population}

Insert text.

\section{Step 3. Select your control
group}\label{step-3.-select-your-control-group}

Insert text.

\section{The fly in the ointment}\label{the-fly-in-the-ointment}

Insert text.

\section{Bibliography}\label{bibliography-2}

Simon SD. Developing a research hypothesis. PMean blog, 1999-08-18.
Available in
\href{http://pmean.com/posts/steps-in-developing-research-hypothesis/}{html
format}.

\bookmarksetup{startatroot}

\chapter{Selecting your research
design}\label{selecting-your-research-design}

This chapter is based on a webpage I wrote in 2016.

\section{Step 1. Decide if you can/should
randomize}\label{step-1.-decide-if-you-canshould-randomize}

Insert text.

\section{Step 2. Consider the advantages/disadvantages of retrospective
versus prospective
research}\label{step-2.-consider-the-advantagesdisadvantages-of-retrospective-versus-prospective-research}

Insert text.

\section{Step 3. Think about the most efficient way to select
subjects}\label{step-3.-think-about-the-most-efficient-way-to-select-subjects}

Insert text.

\section{The fly in the ointment}\label{the-fly-in-the-ointment-1}

Insert text.

\section{Bibliography}\label{bibliography-3}

Steve Simon. So you're thinking about a retrospective chart review.
PMean blog, 2016-05-02. Available in
\href{http://blog.pmean.com/chart-review/}{html format}.

\bookmarksetup{startatroot}

\chapter{Selecting your sample size}\label{selecting-your-sample-size}

This chapter is based on a webpage I wrote in 2010.

I got an email last week from a client wanting to start a new research
project looking at relationships between parenting beliefs and childhood
behaviors. The description of the sorts of things to examine was quite
elaborate, and it ended with the question ``how many families would we
need to have any significant differences if they exist?'' Unfortunately,
all the elaborate information provided did not include the information I
would need to answer this question. Justifying a sample size usually
involves three steps.

\section{Step 1: Define your research
hypothesis.}\label{step-1-define-your-research-hypothesis.}

Not all research requires a research hypothesis, but most research does,
and until you define that hypothesis, it is impossible to make any
progress on calculating an appropriate sample size. This particular
email provided a fair amount of detail that could be used to derive a
hypothesis, but no formal hypothesis was directly stated. I like to use
the PICO format described in Evidence-Based Medicine to help people
formulate a good research hypothesis. A research hypothesis will usually
(but not always) have four elements:

P: patient population. This is the group of patients that you want to
examine.

I: intervention. This is what you do to the group of patients that you
think will help them improve

C: comparison group. This is the group of patients without the
intervention that you want to compare to.

O: outcome. This is the variable that will indicate whether or not the
intervention is successful.

Sometimes the intervention is not really something that you think will
help the patients but rather an exposure that the patients have to
endure that may produce some bad results.

A well-formulated hypothesis is important, because it tells the
statistician what type of statistic is likely to be needed to test the
hypothesis.

\subsection{What do you do if you don't have a research
hypothesis?}\label{what-do-you-do-if-you-dont-have-a-research-hypothesis}

In some research studies, the goal is exploratory. You don't have a
formal hypothesis at the start of the study, but rather you are hoping
that the data you collect will generate hypotheses for future studies.
The path to selecting a sample size in these settings is quite
different. Often you want to establish that the confidence intervals for
some of the key descriptive statistics in these studies has a reasonable
amount of precision.

\section{Step 2: Find an estimate of the variability of your outcome
measure.}\label{step-2-find-an-estimate-of-the-variability-of-your-outcome-measure.}

You've already done a literature review haven't you? If so, search
through the papers in your review that used the same outcome measure
that you are proposing in your study (the O in PICO). Ideally, the
outcome measure will be examined in a group of patients that is close to
the types of patients that you are studying (the P in PICO, or possibly
the C in PICO). This is not always easy, and you will sometimes be
forced to use a study where the patients are quite different from your
patients. Don't fret too much about this, but make a good faith effort
to find the most representative population that you can.

Some clients will raise an objection here and say that their research is
unique, so it is impossible to find a comparable paper. It is true that
most research is unique (otherwise it wouldn't be research). But what
these people are worried about is that their intervention (the I in
PICO) is unique. In these situations, the remainder of the hypothesis is
usually quite mundane: the patients, the comparison group, and the
outcome (P, C, and O in PICO) are all well studied. If you find a study
where the P, C, and O match reasonably well, but the I doesn't, then you
are probably going to get a good estimate of variation.

If there are major dissimilarities because this patient population (P)
is very different than any previously studied patient population, or
because the outcome measure (O) is newly developed by the researcher,
then perhaps a pilot study would be needed to establish a reasonable
estimate of variation.

Sometimes you can infer a standard deviation through general principles.
If a variable is constrained to be between 0 and 100, it would be
impossible, for example, for the standard deviation to be five thousand.
There are formulas relating the range of a distribution to the standard
deviation that can serve in a pinch if no other data is available. If
your outcome measure is a proportion, for example, then the variation is
related to the estimated proportion. Similarly, the variation in a count
variable is related to the mean of the counts. Find a paper that
establishes a proportion or average count in a control group similar to
your control group and any competent statistician will be able to get an
estimate of variation. In some situations, the amount of variation in a
proportion or count is larger than would be expected by the statistical
distributions (binomial and Poisson) traditionally associated with these
measures. Still, a calculation based on binomial or Poisson assumptions
is a reasonable starting point for further calculations.

\section{Step 3: define the minimum clinically important
difference.}\label{step-3-define-the-minimum-clinically-important-difference.}

The minimum clinically significant difference is the boundary between a
difference so small that no one would adopt the new intervention on the
basis of such a meager changer and a difference large enough to make a
difference (that is, to convince people to change their behavior and
adopt the new therapy).

Establishing the minimum clinically relevant difference is a tricky
task, but it is something that should be done prior to any research
study. It's not easy but this is something that you have to do for
yourself. The clinically relevant difference is determined by medical
experts and not by statisticians. Hey, I'm still trying to understand
the difference between good and bad cholesterol; I wouldn't even be able
to start thinking about how much of a change in cholesterol is
considered clinically relevant. You might start by asking yourself ``How
much of an improvement would I have to see before I would adopt a new
treatment?'' Also, try talking with some of your colleagues. And look at
the size of improvements for other successful treatments.

For binary outcomes, the choice is not too difficult in theory. Suppose
that an intervention ``costs'' X dollars in the sense that it produces
that much pain, discomfort, and inconvenience, in addition to any direct
monetary costs. Suppose the value of a cure is kX where k is a number
greater than 1. A number less than 1, of course, means that even if you
could cure everyone, the costs outweigh the benefits of the cure.

For k\textgreater1, the minimum clinically significant difference in
proportions is 1/k. So if the cure is 10 times more valuable than the
costs, then you need to show at least a 10\% better cure rate (in
absolute terms) than no treatment or the current standard of treatment.
Otherwise, the cure is worse than the disease.

It helps to visualize this with certain types of alternative medicine.
If your treatment is aromatherapy, there is almost no cost involved, so
even a very slight probability of improvement might be worth it. But
Gerson therapy, which involves, among other things, coffee enemas, is a
different story. An enema is reasonably safe, but is not totally risk
free. And it involves a substantially greater level of inconvenience
than aromatherapy. So you'd only adopt Gerson therapy if it helped a
substantial fraction of patients. Exactly how many depends on the dollar
value that you place on having to endure a coffee enema, a task that I
will leave for someone else to quantify.

If there are side effects associated with the treatment that only occur
in a fraction of the patients receiving the treatment, then the
calculations are a bit trickier, but still possible in theory. It
becomes more tricky still when different people place different monetary
values on the risks and inconveniences of a new therapy.

For continuous variables, the minimum clinically significant difference
could be defined as above. Define a threshold that represents ``better''
versus ``not better'' and then try to shift the entire distribution so
that the fraction ``better'' under the new treatment is at least 1/k.

There have also been efforts to elucidate, through experiments,
interviews, and other approaches, what the average person considers an
important shift to be. For the visual analog scale of pain, for example,
a shift of at least 15 mm is considered the smallest value that is
noticeable to the average patient.

\section{Bibliography}\label{bibliography-4}

Simon SD. Sample chapter, the first three steps in selecting an
appropriate sample size. PMean blog, 2010-07-24. Available in
\href{http://www.new.pmean.com/chapter-sample-size/}{html format}.

\bookmarksetup{startatroot}

\chapter{Developing your pilot study}\label{developing-your-pilot-study}

This chapter is based on a webpages I wrote in 2007, 2016, 2019, and
2023.

\section{Step 1. Visualize the bigger study in the
future}\label{step-1.-visualize-the-bigger-study-in-the-future}

Insert text.

\section{Step 2. Identify planning
gaps}\label{step-2.-identify-planning-gaps}

Insert text.

\section{Step 3. Think about where ``Murphy's Law'' might
strike}\label{step-3.-think-about-where-murphys-law-might-strike}

Insert text.

\section{The fly in the ointment}\label{the-fly-in-the-ointment-2}

Insert text.

\section{Bibliography}\label{bibliography-5}

Steve Simon. IRB review of a pilot study. PMean blog, 2007-03-26.
Available in \href{http://www.new.pmean.com/irb-review-pilot/}{html
format}.

Steve Simon. So you're thinking about a pilot study. PMean blog,
2016-06-16. Available in \href{http://blog.pmean.com/pilot-study/}{html
format}.

Steve Simon. Slapping the word pilot on a failed study. PMean blog,
2019-03-03. Available in
\href{http://pmean.com/posts/failed-study/}{html format}.

Steve Simon. The best reasons to run a pilot study. PMean blog,
2023-12-06. Available in
\href{http://pmean.com/posts/reasons-to-run-a-pilot/}{html format}.

\bookmarksetup{startatroot}

\chapter{Designing your
questionnaire}\label{designing-your-questionnaire}

This chapter is based on webpages I wrote in 2002, 2005, and 2008.

\section{Step 1. Brainstorm a long list and then prune
back}\label{step-1.-brainstorm-a-long-list-and-then-prune-back}

Insert text.

\section{Step 2. Get opinions from content
experts}\label{step-2.-get-opinions-from-content-experts}

Insert text.

\section{Step 3. Pilot test your
questionnaire}\label{step-3.-pilot-test-your-questionnaire}

Insert text.

\section{The fly in the ointment}\label{the-fly-in-the-ointment-3}

Open ended questions.

\section{Bibliography}\label{bibliography-6}

Boynton PM, Greenhalgh T. Selecting, designing, and developing your
questionnaire. Bmj 2004: 328(7451); 1312-5. doi:
\href{https://doi.org/10.1136/bmj.328.7451.1312}{10.1136/bmj.328.7451.1312}

Simon SD. So you want to write a questionnaire. PMean blog, 2002-07-12.
Available in
\href{http://pmean.com/posts/steps-in-writing-questionnaire/}{html
format}.

Simon SD. Open-ended questions on a survey. PMean blog, 2005-03-25.
Available in \href{http://pmean.com/posts/open-ended-questions/}{html
format}.

Simon SD. How to design a new survey. PMean blog, 2008-10-28. Available
in \href{http://pmean.com/posts/plan-survey/}{html format}.

\bookmarksetup{startatroot}

\chapter{Obtaining ethical approval for your
study}\label{obtaining-ethical-approval-for-your-study}

This chapter is based on a webpage that I wrote in 2002.

\section{Step 1. Establish your credentials as a
researcher}\label{step-1.-establish-your-credentials-as-a-researcher}

Insert text.

\section{Step 2. Demonstrate your concern for privacy
rights}\label{step-2.-demonstrate-your-concern-for-privacy-rights}

Insert text.

\section{Step 3. Prepare a defensible strategy for your data
analysis}\label{step-3.-prepare-a-defensible-strategy-for-your-data-analysis}

Insert text.

\section{The fly in the ointment}\label{the-fly-in-the-ointment-4}

Insert text.

\section{Bibliography}\label{bibliography-7}

Simon SD. Getting IRB approval for your research. PMean blog,
2002-01-01. Available in
\href{http://pmean.com/posts/getting-irb-approval/}{html format}.

\bookmarksetup{startatroot}

\chapter{Setting up your data entry
process}\label{setting-up-your-data-entry-process}

So you have data. It is on paper. Or maybe it is computer-readable, but
the data has no obvious structure. You have to put in a
computer-readable format before you can do any data analysis. You have
three choices: database, spreadsheet, or text file.

If you are ambitious, setting up a database might be your best option.
There are systems like REDCap (Garcia 2021) that have been adopted by
many research organizations. If you are flying solo or if your
organization does not have REDCap, lobby hard for this. You and everyone
you work with will save time and produce better quality data sets. If
you can't convince your boss or if you are flying solo, then still look
at a database solution. Microsoft Access for Windows PCs or Claris
Filemaker for the Macintosh are not free, but well worth the investment.

Designing a database for your data entry slows you down at first, and
this is a good thing. The setup requires you to think about your data
and plan intelligently. This time you invest early in a database will be
rewarded richly once you start actually entering your data.

You might consider using a spreadsheet, like Microsoft Excel or Apple
Numbers. Don't do it! There are a million reasons to avoid spreadsheets
(Cite EUSPRIG, genome problems, row limitations). Some are specific to a
particular spreadsheet, but many are endemic in all spreadsheets.

Sometimes the data is given to you. There is lots of guidance on how to
handle things. The first section of Wilson 2017 is an excellent
resource. If you have a text file, watch out for special characters,
like the non-breaking space (Simon 2020), the smart or curly quotes
(Simon 2020a), leading and trailing blanks (Simon 2007) and especially
the tab character (Simon)

\section{Step 1: Arrange your data in a rectangular
format}\label{step-1-arrange-your-data-in-a-rectangular-format}

Arrange your data in a rectangular format. \textbf{The intersection of
each row and column should contain a single number}. Here's an example
of data which does not fit into a rectangular format. These data are
loosely based on a study of breast feeding in pre-term infants. The data
have been shortened and modified to serve as a simple example of data
entry.

\begin{verbatim}
    Breast feeding status at six months

    No                   Yes                  Lost to follow-up

    Mom's Marital Birth  Mom's Marital Birth  Mom's Marital Birth
    Age   Status  Weight Age   Status  Weight Age   Status  Weight

     18   Married 1.550   28   Single  2.381   28   Married 1.685
     33   Single  1.990                1.130                2.435
     34   Married         26   Married 2.060
     36   Married 1.640
\end{verbatim}

Notice the jagged shape of the data. There is a 4 by 3 block of data
(the No group), and then a 3 by 3 block of data (the Yes group), and
then a 2 by 3 block of data (the Lost to follow-up group). If we stack
these blocks one beneath another rather than one beside another, we will
get a rectangular shape. When we re-arrange the data, however, we need
to include an extra column of information to designate the specific
block/group.

Here is what the data looks like after we re-arrange it into a
rectangular format.

\begin{verbatim}
    Breast
    Feeding  Mom's Marital Birth
    Status   Age   Status  Weight

     No       18   Married 1.550
     No       33   Single  1.990
     No       34   Married      
     No       36   Married 1.640
     Yes      28   Single  2.381
     Yes                   1.130
     Yes      26   Married 2.060
     Lost     28   Married 1.685
     Lost                  2.435
\end{verbatim}

Now you still have some problems here. There are some parts of the
rectangle that are empty. These represents missing data. \textbf{Never
let a empty field represent missing data}. Explicitly create a code for
missing, and be sure to explain why the data are missing to anyone
involved with analysis of your data. In this example, let -1 represent a
missing value for Mom's Age and Birth Weight. Let 9 represent a missing
value for Marital Status.

Here's what the data looks like when we plug up the missing value holes.

\begin{verbatim}
    Breast
    Feeding  Mom's Marital Birth
    Status   Age   Status  Weight

     No       18   Married 1.550
     No       33   Single  1.990
     No       34   Married    -1
     No       36   Married 1.640
     Yes      28   Single  2.381
     Yes      -1      9    1.130
     Yes      26   Married 2.060
     Lost     28   Married 1.685
     Lost     -1      9    2.435
\end{verbatim}

One more change is needed. Your variable names take up three rows of
data. You need to shorten this to one line and get rid of the blank
line.

Picking names is a bit tricky. Short names are okay, but not too short.
If your variable name includes two or more words, you have several
choices. I used an underscore between breast and feeding and status. You
could also use a dot (breast.feeding.status), but be careful with dots.
Some software (Python and SQL are two examples) reserve the dot for
something else.

A dash (minus sign) will not work because breast-feeding-status will
look like a mathematical sequence of subtractions. Spaces don't work
either because ``breast feeding status'' will be interpreted some some
software as three variables: breast, feeding, and status.

You can also just run the words together, but this can cause confusion.
I remember in the early data of the web a group called Writer's Exchange
decided to create a website, www.writersexchange.com. Then someone
noticed that this address could be misinterpreted as ``writer sex
change''.

If you don't use an underscore or dot to separate you can use initial
capitalization, such as BreastFeedingStatus or breastFeedingStatus. You
may want to use the techie word ``CamelCase'' for this approach. And
underscores are ``snake case''. Now don't you sound smart!

Here are the choices I made, but other choices are okay as well.

\begin{verbatim}
breast_feeding_status age_mother marital_status birth_weight
                   No        18         Married        1.550
                   No        33          Single        1.990
                   No        34         Married           -1
                   No        36         Married        1.640
                  Yes        28          Single        2.381
                  Yes        -1               9        1.130
                  Yes        26         Married        2.060
                 Lost        28         Married        1.685
                 Lost        -1               9        2.435
\end{verbatim}

Why not use abbreviations like ``bf'' for breast feeding status and
``bw'' for birth weight? Well you could. You'll save a bit of typing
later. I used to abbreviate a lot, but I don't do it as much, partly
because of the advice in Wilson 2017 and partly because I kept
forgetting if the abbreviation was ``bw'' for birth weight or ``bwt''.
If you always spell things out, you will never have to remember which
abbreviation you used. Now there are some abbreviatios, like bmi for
body mass index, that are in such common use that you can use them
safely.

Consistency is also important. Don' combine age\_mother with
marital.status and BirthWeight.

There you have it. A nice rectangular grid with the intersection of
every row and column containing one and only one number.

Now, the ``only one'' is also very important. You might be tempted to
save a bit of space by combining two pieces of data into one. This is an
example of the old adage ``penny wise and pound foolish''. Whatever
savings you achieve by combining two pieces of data together is lost ten
times over during your data analysis.

As an example, suppose you create a clever number and letter code where
44M represents a 44 year old male and 50F represents a 50 year old
female. Don't do it. When you important that composite column into any
statistical software program, you will find that you can't compute even
simple statistics like the average age or the proportion of females
without taking the time to split apart that data that you have squished
together.

Another example of ``penny wise but pound foolish'' is representing
blood pressure as systolic/diastolic. if you feed in values like 120/90
and 150/100, your software will not know what to do. If it did do
something, it would be a disasterous conversion of 120/90 to 1.25 and
150/100 to 1.5. Put systolic blood pressure in one column and diastolic
blood pressure in a separate column.

\section{Step 2: Create codes for categorical
data}\label{step-2-create-codes-for-categorical-data}

Add text.

\section{Step 3: Document missing
values}\label{step-3-document-missing-values}

Add text.

\section{The fly in the ointment: longitudinal and repeated measures
data}\label{the-fly-in-the-ointment-longitudinal-and-repeated-measures-data}

Add text.

\section{Bibliography}\label{bibliography-8}

Kristin Briney. Data dictionaries. Data Ab Initio blog, August 5, 2014.
Available in \href{http://dataabinitio.com/?p=454\%C2\%A0.}{html
format}.

Broman KW, Woo KH. (2018). Data Organization in Spreadsheets. The
American Statistician, 72(1), 2--10. doi:
\href{https://doi.org/10.1080/00031305.2017.1375989}{10.1080/00031305.2017.1375989}.

Garcia KKS, AbrahÃ£o AA. Research Development Using REDCap Software.
Healthc Inform Res. 2021 Oct;27(4):341-349. doi:
\href{https://doi.org/10.4258/hir.2021.27.4.341}{10.4258/hir.2021.27.4.341}.

REDCap consortium. REDCap: Research Electronic Data Capture. Available
in {[}html format{]}{[}ref-redcap- nodate{]}.

Neil Saunders. When life gives you coloured cells, make categories. What
You're Doing is Rather Desperate blog, 2014-08-04. Available in
\href{https://nsaunders.wordpress.com/2014/08/06/when-life-gives-you-coloured-cells-make-categories/}{html
format}.

Simon SD. General guide to data entry. PMean blog, 1999-09-03. Available
in \href{http://pmean.com/posts/steps-in-data-entry/}{html format}.

Simon SD. Inputting a two-by-two table into SPSS. PMean blog,
1999-09-18. Available in
\href{http://pmean.com/posts/two-by-two-table-in-spss/}{html format}.

Simon SD. Spreadsheet or Database? PMean blog, 2000-01-28. Available in
\href{http://pmean.com/posts/spreadsheet-or-database/}{html format}.

Simon SD. Watch out for ambiguous data. PMean blog, 2007-02-14.
Available in \href{http://pmean.com/posts/ambiguous-data/}{html format}.

Simon SD. Naming conventions for variables. PMean blog, 2008-07-30.
Available in \href{http://www.pmean.com/08/NamingConventions.html}{html
format}.

Simon SD. A false sense of frugality. PMean blog, 2008-12-17. Available
in \href{http://www.pmean.com/08/FalseFrugality.html}{html format}.

Simon SD. Those pesky tab characters. PMean blog, 2012-03-21. Available
in \href{http://pmean.com/posts/pesky-tabs/}{html format}.

Simon SD. Identifying and manipulating non-breaking spaces. PMean blog,
2020-01-07. Available in
\href{http://pmean.com/posts/smart-quotes/}{html format}.

Simon SD. Smart quotes, em dashes, and en dashes. PMean blog,
2020-03-02. Available in
\href{http://pmean.com/posts/non-breaking-spaces/}{html format}.

Simon SD. Reading text files. PMean blog, 2020-04-30. Available in
\href{http://pmean.com/posts/reading-text-files/}{html format}.

Wagner L. Snake Case or Camel Case? A Guide to Programming Naming
Conventions. Boot.Dev blog, 2024-10-31. Available in
\href{https://blog.boot.dev/clean-code/casings-in-coding/}{html format}.

Wilson G, Bryan J, Cranston K, Kitzes J, Nederbragt L, Teal TK (2017)
Good enough practices in scientific computing. PLoS Comput Biol
13(6):e1005510. Available in
\href{https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510}{html
format}.

\bookmarksetup{startatroot}

\chapter{Running a descriptive data
analysis}\label{running-a-descriptive-data-analysis}

This chapter is based on a webpage I wrote in 2001.

\section{Step 1: Know your count}\label{step-1-know-your-count}

Add text.

\section{Step 2: Compute ranges and
frequencies}\label{step-2-compute-ranges-and-frequencies}

Add text.

\section{Step 3: Examine relationships using crosstabs, boxplots, and/or
scatterplots}\label{step-3-examine-relationships-using-crosstabs-boxplots-andor-scatterplots}

Add text.

\section{The fly in the ointment: ordinal
data}\label{the-fly-in-the-ointment-ordinal-data}

Add text.

\section{Bibliography}\label{bibliography-9}

Steps in a descriptive model. 2001-10-11. Available in
\href{http://pmean.com/posts/steps-in-descriptive-model/}{html format}.

\bookmarksetup{startatroot}

\chapter{Running a linear regression
analysis}\label{running-a-linear-regression-analysis}

This chapter is based on webpages I wrote in 1999, 2002, and 2003.

There are two quotes worth mentioning here.

\emph{Let no man ignorant of geometry enter} - Sign over Plato's Academy
in Athens

\emph{Well, Mr Snelgrove, I happen to know that in the future I will not
have the slightest use for algebra, and I speak from experience.} -
Peggy Sue Got Married.

In my talks, I often ask the question, did you like High School Algebra.
I get a mix of responses: some people loved it, some hated it, but most
were indifferent. Fair enough, but if you want to run a linear
regression analysis, you can't be indifferent. If nothing else, you have
to remember the formula you learned in algebra for a straight line.

\(y = mx + b\)

The slope, m, represents the change in y divided by the change in x. The
intercept, b, represents where the line crosses the y-axis.

The linear regression formula is a bit different.

\(\hat{y}_i=\hat\beta_0+\hat\beta_1 X_i\)

where the slope, \(\hat\beta_1\) represents the estimated average change
in Y when X increases by one unit and the intercept, \(\hat\beta_0\),
represents the estimated average value of Y when X equals zero.

\section{Step 1: Plot your data}\label{step-1-plot-your-data}

I've always loved linear regression because it is so visual. You learn a
lot before you compute any statistics by looking at graphs.

\pandocbounded{\includegraphics[keepaspectratio]{chapters/../images/figure-11-01.png}}

I added the trend line. You should try to eyeball the slope and
intercept from your graph. You want to see if these values pass the
``smell test.'' Do they seem reasonable or is something a bit fishy and
warrants further investigation.

Here is how you calculate the slope. A thousand square foot house is
predicted to sell for about 70 thousand dollars. A three thousand square
foot house is predicted to sell for about 190 thousand dollars. These
are just rough estimates. Don't worry if you don't get them quite right.

The slope is the change in Y (120 thousand dollars) divided by the
change in X (2 thousand square feet), which produces a rough estimate of
your slope, 60 dollars per square foot. That passes the smell test. It
seems eminently reasonable, especially considering that these are 1993
houses.

To calculate the intercept, you need to redraw the graph so that you can
read the prediction at x=0. Here's what that graph looks like. I
extended the line beyond the range of the data, which is a something
that you should do with great caution.

\pandocbounded{\includegraphics[keepaspectratio]{chapters/../images/figure-11-02.png}}

The intercept appears to be just a tad above zero. Call it five thousand
dollars. Now does it make sense to pay five thousand dollars for a house
of zero square feet? You might argue that the five thousand dollars
represents the estimated average price for an empty lot, perhaps.
Perhaps not. If you are a bit skeptical of this interpretation, you are
probably justified in that skepticism. It is quite a bit of an
extrapolation.

The importance of the eyeball estimates is that they greatly reduce the
fear and intimidation that you might feel when you actually run your
regression analysis. You will be looking for two friends, the slope of
around 60 and the intercept of around five thousand. When you see those
friends in your regression table, you will get some reassurance that you
are doing things properly.

Now if your regression model includes categorical variables, display
them using boxplots. You might suspect that custom built houses will be
a bit pricier, and looking at the boxplot, you'd be right!

\pandocbounded{\includegraphics[keepaspectratio]{chapters/../images/figure-11-03.png}}

I added the means (small plus signs) and a line connecting them to this
boxplot. The estimated average price of a regular home appears to be
around 95 thousand dollars. The average price for a custom-built house
is around 145 thousand dollars, about 50 thousand dollars more. When you
run the regression model predicting price from the custom-built
indicator, look for two friends, a slope of 50 thousand dollars and an
intercept of 95 thousand dollars.

If you plan to look at the joint effects of size and custom-built, take
some time to evaluate how these two independent variables relate to one
another. A boxplot works well here.

\pandocbounded{\includegraphics[keepaspectratio]{chapters/../images/figure-11-04.png}}

This box plot shows an interesting pattern that you probably were
expecting. Custom-built houses are also bigger houses. The two
independent variables are positively correlated. This is not a fatal
problem, but you should use some care when trying to disentangle the
individual effects of each variable.

Now if you have a lot of independent variables (five or more is a lot),
you may not have the time and luxury of looking at every
interrelationship among your independent variables. A correlation matrix
might still be useful. Here is the correlation matrix between the two
independent variables and the dependent variable. I am not rounding the
values here, but you should round to two significant figures in any
report that you prepare.

Table 11-1. Correlations

\begin{verbatim}
             price      sqft  i_custom
price    1.0000000 0.8447951 0.5552920
sqft     0.8447951 1.0000000 0.5201016
i_custom 0.5552920 0.5201016 1.0000000
\end{verbatim}

The correlations are all large and positive, which passes the smell
test.

\section{Step 2: Compute a simple
model}\label{step-2-compute-a-simple-model}

There are two types of models, crude models and adjusted models. A crude
model looks at how a single factor affects your outcome measure and
ignores potential covariates. An adjusted model incorporates these
potential covariates. Start with a crude model. It's simpler and it
helps you to get a quick overview of how things are panning out. Then
continue by making adjustments for important confounders.

A crude model for comparing duration of breast feeding to feeding group
would be a t-test. I prefer

however to present a general linear model because it provides a unifying
framework for diverse statistical methods like analysis of variance
analysis of covariance, multiple linear regression repeated measures
designs and t-tests. Shown below is the table of tests from the general
linear model procedure.

The general linear model uses an F test instead of the t test

but in this context these two tests are mathematically equivalent. The
p-value for comparing feeding groups is .001 which indicates a
significant difference between the two groups. The general linear model
also has a table of estimates

which is presented below.

The intercept represents the average duration of breast feeding for the
NG tube group. We see that the average duration is 20 weeks for the NG
tube group. The (FEED\_TYP=1) term is an estimate of how much the
average duration changes when we move from the NG tube group to the
bottle group. We see that the bottle group has an average duration that
is 7 weeks shorter.

Shown below is a table of means from the general linear model.

We see that the difference between the two means is roughly 7 weeks,
which confirms the results shown previously.

\section{Step 3: Examine residuals}\label{step-3-examine-residuals}

\section{Step 4: Compute an adjusted
model}\label{step-4-compute-an-adjusted-model}

but could some of all of this difference be due to the fact that the NG
tube group had older mothers? To answer this we need to fit an adjusted
model. Shown below is the table of tests for a general linear model that
includes mother's age in the model.

This table shows that the effect of bottle feeding is to decrease
duration of breast feeding by about six weeks

after adjusting for mother's age. Each year that a mother is older
increase the duration of breast feeding by a quarter of a week. A
previous descriptive analysis of this data revealed that the average age
for mothers in the treatment group is 29 years and the average age for
mothers in the control group is 25 years. When you see a discrepancy
like this in an important covariate

you need to assess whether the four year gap in average ages could
account for part or all of the effect of the treatment group. This
analysis shows that the four year gap only accounts for a small portion
of the difference. Since each year of age changes the duration by a
quarter week

this means that the difference between mother's ages acounts for just
one week in the 7 week difference we saw in the crude model. Shown below
is the table of means.

This table now adjusts for mother's age. The mean for the bottle fed
group is adjusted upward to what it would be if the average age of the
mothers in this group were 27 rather than 25. The mean for the NG tube
group is adjusted downward to what it would be if the average age were
27 instead of 29. Note that the adjusted mean duration is half a week
higher than the crude mean duration in the bottle group and that the
adjusted mean duration is half a week lower than the crude mean duration
for the NG tube group. This confirms that the difference between the two
feeding groups is roughly 6 weeks

after adjusting for mother's age. This is one week less than the crude
model. This is not the final model. We should examine the effect of
delivery type and account for the fact that we have some data on twins.
I hope, though

that this presentation gives you a general idea of what crude and
adjusted models are.

\section{The fly in the ointment: clustered
data}\label{the-fly-in-the-ointment-clustered-data}

**Step 3

Analyze predicted values and residuals**. A regression model gives you
an equation that you can use to compute predicted values and residuals.
In the regression model with mother's age and feeding type

the equation (with a bit of rounding) is age\_stop = 13 + 0.25 * age - 6
* feed\_typ,

where feed\_typ=1 if control

0 if treatment. So

for example if you recruited a mother into the treatment group and she
was 30 years old you would predict the duration of breast feeding to be
predicted age\_stop = 13 + 0.25 * 30 - 6 * 0 = 20.5 weeks.

If you recruited a mother into the treatment group and she was 19 years
old

you would predict the duration of breast feeding to be predicted
age\_stop = 13 + 0.25 * 19 - 6 * 0 = 17.75 weeks.

If you recruited a mother into the control group and she was 37 years
old

you would predict the duration of breast feeding to be predicted
age\_stop = 13 + 0.25 * 37 - 6 * 1 = 16.25 weeks.

Now it turns out that the first three rows of your data set correspond
to the three scenarios described above. The actual values we observed
were 30 weeks

4 weeks and 12 weeks. The residual is the difference between what we
observed in the data and what the regression model would have predicted.
For the first mother in the sample

you can observe that there are 30 weeks of breast feeding, but the model
predicted much less 20.5 weeks. You can compute residual = 30 - 22.5 =
7.5.

When the residual is positive

your regression model has under-predicted the outcome. With the second
mother your regression model has over-predicted the outcome. The
observed value is 4 and the predicted value is 17.75. So you can compute
residual = 4 - 17.75 = -13.75.

This residual is negative. For the third mother

the residual is also negative. residual = 12 - 16.25 = -4.25.

Most statistical models require certain assumptions to be made about
your data. These assumptions can be examined using residuals. If your
model is good

the residuals show a random featureless scatter. If instead they show a
systematic trend or pattern then you can improve by incorporating that
trend or pattern into your model. The simplest plot is a plot of
predicted values versus residuals (shown below).

The relatively random scatter of data values provides us with confidence
in the assumptions of the linear model. There is no obvious trend or
pattern in this plot.

I also looked at the residuals versus the feeding groups and versus
mother's age. Both showed no systematic trend or pattern (graphs not
shown).

The following plot examines normality of the residuals.

The curved line indicates a non-normal distribution. Further
investigation would identify that this distribution is rectangular: it
has a sharp lower and upper bound that differs from a bell shaped curve.
The design of this study produces these limits because the age at which
the mother stops breast feeding can't be shorter than 0 weeks and it
can't be longer than the duration of the study (roughly 6 months). In
practice

this type of non-normality is not a serious problem. Summary

There are three steps in a typical linear regression model analysis.

Fit a crude model. Fit an adjusted model. Examine predicted values and
residuals. You can find an earlier version of this page on my original
website.

Excluding direct quotes from outside sources, all text is in the public
domain. Images are copyrighted unless noted

\section{Bibliography}\label{bibliography-10}

UCLA Statistical Consulting Group. Regression Analysis \textbar{} SAS
Annotated Output. Available in
\href{https://stats.oarc.ucla.edu/sas/output/regression-analysis/}{html
format}.

Steve Simon. Steps in a typical linear regression analysis. PMean blog,
1999-09-21. Available in
\href{http://new.pmean.com/steps-in-linear-regression/}{html format}.

Steve Simon. Interpreting coefficients in a linear regression model.
PMean blog, 2002-06-24. Available in
\href{http://new.pmean.com/intepreting-linear-regression-coefficients/}{html
format}

Steve Simon. Building a complex model. PMean blog, 2003-04-23. Available
in \href{http://new.pmean.com/building-complex-models/}{html format}.

Steve Simon. Joke about the dangers of extrapolation. Pmean blog,
2021-11-27. Available in
\href{http://new.pmean.com/extrapolation-joke/}{html format}.

\bookmarksetup{startatroot}

\chapter{Running a logistic regression
analysis}\label{running-a-logistic-regression-analysis}

This chapter is based on web pages I wrote in 1999 and 2002.

\section{Step 1: Examine raw
probabilities}\label{step-1-examine-raw-probabilities}

Examine raw probabilities using crosstabs

Add text.

\section{Step 2: Compute a simple
model}\label{step-2-compute-a-simple-model-1}

Add text.

\section{Step 3: Compute an adjusted
model}\label{step-3-compute-an-adjusted-model}

Add text.

\section{The fly in the ointment: clustered
data}\label{the-fly-in-the-ointment-clustered-data-1}

Add text.

\section{Bibliography}\label{bibliography-11}

Simon SD. Guidleins for logistic regression models. PMean blog,
1999-09-27. Available in
\href{http://pmean.com/posts/steps-in-logistic-regression/index.html}{html
format}.

Simon SD. The concepts behind the logistic regression model. PMean blog,
2002-07-23. Available in
\href{http://pmean.com/posts/logistic-regression-concepts/}{html
format}.

\bookmarksetup{startatroot}

\chapter{Running a multi-factor analysis of variance
model}\label{running-a-multi-factor-analysis-of-variance-model}

This chapter is based on a webpage that I wrote in 2003.

When your grouping variable has two levels, the t-test and ANOVA are
{[}identical{]}{[}hun1{]}. It's sort of like arguing over whether to buy
twelve doughnuts or a dozen.

If you take the t-statistic in the t-test and square it, you get the
F-statistic in ANOVA.

The time where there is a difference is when the group has three or more
levels. Say, for example, that the group has levels A, B, C, and D. Then
you could do a t-test on A vs B, A vs C, A vs D, B vs C, B vs D, and C
vs D. That's a lot of work. With ANOVA you get one test that examines
whether the null hypothesis H0 muA = muB = muC =muD. The alternative
hypothesis is that at least two of the means are unequal. That's kind of
vague, so if you reject the null hypothesis, then you should do some
sort of follow-up test (like Tukey) to see exactly where the differences
are.

The place where ANOVA really shines is when you have two categorical
variables that might influence your outcome measure. You get the
opportunity to examine the impact of each categorical predictor AND get
the opportunity to examine how the two categorical variables interact
with each other.

If you have three or more categorical predictors, well then the fun
increases. There are all sorts of interactions to work with.

Actually, I need to warn you. Finding an interaction is a good thing. It
helps you understand better how to approach a difficult health care
problem. There may be synergy. Here's a hypothetical scenario. A low
calorie diet helps you lose little weight. A high intensity exercise
program helps you lose little weight. But put the two together and BAM!
You lose a lot of weight.

It could be the opposite, an antagonistic interaction. Here is a
different hypothetical scenario. A low calorie diet helps you lose a lot
of weight. A high intensity exercise program helps you lose a lot of
weight. But the combination is disappointing. The low calorie diet
leaves you with too little energy for your high intensity exercises. And
after a high intensity workout, you recover at the Cheesecake Factory.

Now I am not an expert in how to lose weight and my current girth is a
testament to that ignorance. The whole point is that health care is
building blocks. You can expect something as simple as stacking three of
four blocks together to make a tall tower.

The hard works starts when you discover an interaction, synergistic,
antagonistic, or something else. You can't just say that after six
months, a low calorie diet will reduce your weight by 10 pounds, a high
intensity exercise program will reduce your weight by 5 pounds, so the
sure fire way to lose 15 pounds is to combine the two. You have to
compare the effect of diet alone to the no diet, no exercise group,
compare the effect of exercise alone to the no diet, no exercise group,
and then compare both of them to the diet combined with exercise group.
This is not terribly difficult, but it is tedious. You have to use a lot
more words when you try to describe what is going on.

\section{Step 1: Plot your data}\label{step-1-plot-your-data-1}

Look for interactions

\section{Step 2: Fit individual
models}\label{step-2-fit-individual-models}

Add text.

\section{Step 3: Fit multi-factor
models}\label{step-3-fit-multi-factor-models}

Add text.

\section{The fly in the ointment: unbalanced
data}\label{the-fly-in-the-ointment-unbalanced-data}

Add text.

\section{Bibliography}\label{bibliography-12}

Simon SD. Steps in a typical ANOVA model. PMean blog, 2003-06-20.
Available in \href{http://pmean.com/posts/steps-in-anova/}{html format}.

\subsubsection{Dear Professor Mean,}\label{dear-professor-mean}

I wanted to compare two groups in my research, those who completed every
test battery, and those who completed only some of them. I ran ANOVAs on
age, iq, adhd score, and so forth. My professor says that I should have
used a t-test instead. Why can't I use ANOVA. Isn't ANOVA better than a
t-test? --Angry Anastasia*

\subsubsection{Dear Anastasia}\label{dear-anastasia}

When your grouping variable has two levels, the t-test and ANOVA are
{[}identical{]}{[}hun1{]}. It's sort of like arguing over whether to buy
twelve doughnuts or a dozen.

The time where there is a difference is when the group has three or more
levels. Say, for example, that the group has levels A, B, C, and D. Then
you could do a t-test on A vs B, A vs C, A vs D, B vs C, B vs D, and C
vs D. That's a lot of work. With ANOVA you get one test that examines
whether the null hypothesis H0 muA = muB = muC =muD. The alternative
hypothesis is that at least two of the means are unequal. That's kind of
vague, so if you reject the null hypothesis, then you should do some
sort of follow-up test (like Tukey) to see exactly where the differences
are.

If you take the t-statistic in the t-test and square it, you get the
F-statistic in ANOVA.

Here's how you would run a t-test in SPSS. First, select ANALYZE
\textbar{} COMPARE MEANS \textbar{} INDEPENDENT SAMPLES T-TEST from the
menu.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.56.gif}}

In the dialog box, place the outcome variable in the TEST VARIABLE(S)
field and the categorical variable in the GROUPING VARIABLE field. You
then define what the two group levels are by clicking on the dialog box.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.57.gif}}

In this example, the groups are represented by the strings ``Control''
and ``Treatmen''. Click on the CONTINUE button and then the OK button of
the previous dialog box.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.58.gif}}

The output from SPSS starts out nicely enough. SPSS tells you that the
control group has 44 patients, a mean of 13.32, a standard deviation of
9.981, and a standard error (standard deviation divided by the square
root of the sample size) of 1.505. The treatment group has fewer
patients, 38, and the mean is much larger. The standard deviation and
standard error for the treatment group are roughly the same as the
controls.

Unfortunately, the second table in SPSS is so wide that it is hard to
display well on your computer screen or in the web page. I split the
second table into four pieces.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.59.gif}}

SPSS provides two different versions of the t-test. The first row,
labeled ``Equal variances assumed,'' gives the traditional t-test, which
uses a pooled estimate of variance. The second row, labeled ``Equal
variances not assumed,'' gives an alternative version that uses a
Satterthwaite approximation. I feel that presenting two versions of the
same test is needlessly confusing, but unfortunately, SPSS does not give
you a way to turn one or the other.

As a general rule, I encourage people to use the traditional t-test
(Equal variances assumed row) unless you have a strong a priori reason
to believe that the two groups have markedly different variances. Other
people will recommend that you choose the Satterthwaite approximation
(Equal variances not assumed row) because that test requires fewer
assumptions. A third group of people will run a statistical test and
then choose the row based on that statistical test.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.60.gif}}

The second part of this table shows Levene's test for equality of
variances. I dislike Levene's test for a variety of reasons, and it
turns out that you can safely ignore this part of the table. If you
belong to that third camp of people described above, then you would
choose the Equal Variances Assumed row when Levene's test was not
statistically significant, and the Equal Variances Not Assumed row when
Levene's test was statistically significant. I dislike this approach,
because it is the magnitude of the deviation from equality rather than
the statistical significance of the deviation from equality that is
important.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.61.gif}}

The third part of the table gives the t-test. I would usually select the
t-test in the first row, but notice here that there is very little
difference in the t-statistics, and the p-values are identical. Since
the p-value is small, we would conclude that there is a statistically
significant difference between the treatment and control groups in
average duration of breast feeding.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.62.gif}}

The final portion of the table provide the mean difference, the standard
error for this difference and the confidence interval. SPSS computes the
mean difference as Group 1 - Group 2. In this case, this means the
control group minus the treatment group. If you prefer to compute the
difference as Group 2 - Group 1, then simply negate and reverse the
confidence limits. This would make the mean difference +7.050 and the
95\% confidence interval would be 2.788 to 11.312.

Since the 95\% confidence interval excludes the value of zero, we would
conclude again that there is a statistically significant difference
between the treatment and control groups. Furthermore, this difference
is large--at least 2.8 weeks, even after allowing for sampling error.

Now let's compute the same statistic using an ANOVA model. Select
ANALYZE \textbar{} GENERAL LINEAR MODEL \textbar{} UNIVARIATE from the
SPSS menu.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.63.gif}}

Be sure to click on the OPTIONS button.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.64.gif}}

The output appears in several nicely formatted tables.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.65.gif}}

Next

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.66.gif}}

Then

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.67.gif}}

Finally,

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.68.gif}}

The situation changes, however, when you have three or more groups. Here
is some data on critical flicker frequency measured on nineteen people.
According to the web page where I got this data

An individual's critical flicker frequency is the highestfrequency at
which the flicker in a flickering light source can be detected. At
frequencies above the critical frequency, the light source appears to be
continuous even though it is actually flickering. --{[}Description taken
from the OzDASL website{]}{[}ozd1{]}

In this data set, the eye color was recorded along with the critical
flicker frequency. Here is a boxplot of the data.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.21.gif}}

Notice that brown eyes tend to have the low flicker frequency and blue
eyes tend to have high flicker. Here are the means and standard
deviations for the three groups.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.32.gif}}

It looks like there is a large difference between these three groups,
but could this be caused by sampling error? To answer this question, you
have to compute how much variation there is among these three means and
compare that to variation within each group.

Variation within groups is often called within subject variation or
error variation and is denoted by SS\textsubscript{within} or SSW.
Another abbreviation commonly used is SSE, with the E standing for
Error.

Within subject variation is a measure of the deviation of each
individual data point from the mean for each group. The figure below
shows these deviations for the flicker data set.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.within.ss.gif}}

You can consider the mean for each group (the brown, green, and blue
lines shown above) as the predicted value based on group knowledge. In
other words, if you only knew the color of a person's eyes, your best
estimate for flicker would be the average that you observed for that
particular eye color. The symbol \^{} above Y represents the predicted
value. Here are the calculations for within subject variation:

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.23.gif}}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.24.gif}}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.25.gif}}

The calculations shown above may be slightly different from the ones you
have seen before. The formulas shown here have an easy generalization to
more complex ANOVA and regression models.

Variation among the group means is often called between subject
variation and is denoted by SS\textsubscript{between}. or SSB

Between subject variation is a measure of how much the group means
differ from the overall mean. The figure below shows these deviations
for the flicker data set.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.between.ss.gif}}

Here are the calculations for variation between groups (SSB)

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.26.gif}}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.27.gif}}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.28.gif}}

ANOVA models will usually also present a third source of variation,
total variation, whic is denoted by SS\textsubscript{Total} or SST.

Total variation is a measure of how much the individual values differ
from the overall mean. The figure below shows these deviations for the
flicker data set.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.total.ss.gif}}

Here are the calculations for total variation (SST)

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.29.gif}}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.30.gif}}

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.31.gif}}

Notice that SST (61.31) is equal to SSW (38.31) plus SSB (23.00).

With a bit of algebra, you could show that total variation is always
equal to between subject variation plus within subject variation. Each
of the three sources of variation has degrees of freedom associated with
it.

Between subject variation and within subject variation are often called
``explained'' and ``unexplained'' variation, respectively. Explained
variation is the variation that can be accounted for by using the group
means and the remaining vaation is unaccounted for. The ratio of
explained variation to total variation is known as R-squared. A value
close to 1 indicates that your ANOVA model has accounted for most of the
variation in the data. This is good news! A value close to 0 indicates
that your ANOVA model has accounted for very little of the data. When
R-squared is small, you should consider measuring other variables and
factors that may explain more of the variation in your data.

In this example, R-squared is 23.00 / 61.31 = 0.38. Roughly 38\% of the
variation in critical flicker rate can be accounted for by eye color.

\subsubsection{Degrees of freedom and mean
squares}\label{degrees-of-freedom-and-mean-squares}

The degrees of freedom represent the number of independent pieces of
information used to compute that source of variation. Typically, it is
the number of data values minus the number of estimated parameters. For
example, the calculation for within subject variation used all 19 data
points, and had 3 estimated means, so the degrees of freedom would be
16. The calculation for between subject variation used not the 19 data
points, but the 3 group means.\textless U+FFFD\textgreater{} We
estimated the deviation from a single overall mean. So the degrees of
freedom for between subject variation is 3-1=2. By a similar argument,
the degrees of freedom for total variation would be 18.

If you let N equal the number of data points in your sample and K equal
the number of groups in your sample, then the degrees of freedom for
within, between, and total variation would be N-K, K-1, and N-1
respectively.

When you divide a source of variation by its degrees of freedom, you get
a mean square, which is a type of adjustment to each source of variation
for the sample size and complexity of your ANOVA model.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.11.gif}}

The mean squares provide several valuable estimates in your ANOVA model.
For example, the square root of MSW is a good estimate of the standard
deviation of the error terms in your ANOVA model. Most of formulas for
confidence intervals in the ANOVA model will include this term.

The ratio between MSB and MSW, often called the F Ratio, is another
important statistic.

The F Ratio is a measure of whether the variation between the group
means is large or small relative to sampling error. When the F Ratio is
close to 1, there is little evidence of differences between the groups,
since the differences among the group are about the size that you would
expect just from sampling error. When the F Ratio is large, there is
strong evidence of statistical differences between the groups, much
larger than could be accounted for by sampling error.

SPSS and most other statistical software will summarize all of the
statistics described above in an ANOVA table. The general form of the
ANOVA table is

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.13.gif}}

Here is how SPSS displays the ANOVA table. SPSS provides additional
information in the first, second, and fifth rows of this table, which
really isn't too important for most situations. The third, fourth, and
sixth rows of the SPSS table represent what is traditionally reported.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.33.gif}}

For this table, the F ratio is 4.802 (remember that we are ignoring the
first two rows of the ANOVA table). This is a large value, and the
p-value is 0.023, which is small and statistically significant.
Therefore, we would conclude that there is indeed a difference among the
three eye colors in the average critical flicker frequency.

Notice the R Squared value listed at the bottom of this table which
matches the value that we calculated above. Adjusted R Squared is
similar measure to R Squared with an adjustment based on the degrees of
freedom in the model. The adjustment provides a bit of discouragement
from using overly complex models, but selecting between models with
differing levels of complexity is Adjusted R Squared provides a moderate
penalty for overly complex models. This is good, but perhaps the penalty
for complexity needs to be stiffened. Selecting among different ANOVA
models is quite challenging.

\subsubsection{Estimating mean
differences}\label{estimating-mean-differences}

Once you have established the statistical significance, you should
examine the size of the differences between the group means. To do this
effectively, you need to create indicator variables.

An indicator variable has two possible values, 1 and 0, representing the
presence or absence of some value. Indicator variables are very useful
for understanding how categorical variables behave.

In the flicker data set, there are three possible indicator variables.
You can indicate the presence of absence of brown eyes, of green eyes,
or of blue eyes. Here's how you would create an indicator variable for
brown eyes. First, select TRANSFORM \textbar{} COMPUTE from the SPSS
menu. A dialog box like the one shown below will appear.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.14.gif}}

The numeric expression (Colour=``Brown'') runs a test on each row of the
data. When the test is true, a value of 1 is computed and when the test
is false, a value of 0 is computed. You create indicator variables for
green and blue by changing the numeric expression to (Colour=``Green'')
or (Colour=``Blue'').

Be careful with this approach if you have any missing values for Colour.

Another approach that works well for creating indicator variables is to
select TRANSFORM \textbar{} RECODE \textbar{} INTO DIFFERENT VARIABLES
from the SPSS menu.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.15.gif}}

Put the name of the indicator variable in the OUTPUT VARIABLE window and
click on the CHANGE button. Then click on the OLD AND NEW VALUES button.
This brings up another dialog box.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.16.gif}}

Designate the category of interest in the OLD VALUE field and use 1 in
the NEW VALUE field. Then select the SYSTEM OR USER MISSING option
button on the left side and the SYSTEM MISSING option button on the
right side. Finally, select the ALL OTHER VALUES option button on the
left side and use 0 in the NEW VALUE field. When you are finished, the
dialog box should look like this:

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.17.gif}}

Click on the CONTINUE button and then the OK button.

Although it is possible to create three different indicator variables
for the three different eye colors, it turns out that only two
indicators are really needed. Let's create a second indicator for green
eyes, but leave out (for now) the indicator for blue eyes. Here's what
your data set looks like after you create these two indicator variables.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.18.gif}}

To estimate differences in means, use the two indicator variables as
covariates in a general linear model.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.19.gif}}

Normally, you would reserve the covariate field for continuous
variables, but it turns out that indicator variables also work well
here. Be sure to click on the OPTIONS button and select DESCRIPTIVE
STATISTICS and PARAMETER ESTIMATES in the dialog box that opens.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.34.gif}}

The interpretation of this table is interesting. The intercept equals
the average flicker for blue eyes. The slope for the indicator for brown
eyes equals the average difference between brown and blue (-2.579 =
25.588 - 28.167). The slope for the indicator for green eyes equals the
average difference between green and blue eyes (-1.247 = 26.920 -
28.167). It turns out that the one indicator out of the three that you
leave out of the model ends up being the center of attention!

Suppose that we had included indicators for green and blue. The
parameter estimates change to the following:

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.35.gif}}

The intercept is now the average for brown and the indicators represent
the average differences of green from brown (1.333 = 26.920 - 25.587)
and blue from brown (2.579 = 28.167 - 25.587).

When you run an ANOVA model, you have to decide to leave one of the
indicator variables out. The category for that indicator becomes the
reference level, and all comparisons will be made with respect to this
reference level.

The choice of reference level is not always obvious. If one of the
categories represents a control group, then this is a logical choice.

If you include the variable ``Colour'' as a fixed factor, what does SPSS
do? It turns out that SPSS will choose the largest value as the
reference level. With strings, the largest value is the one that appears
last in alphabetical order.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.36.gif}}

\subsubsection{Confidence interval}\label{confidence-interval}

The table of parameter estimates provides simple confidence intervals
for the mean differences, but there are two problems with this. First,
with three groups, the parameter estimates table only produces two of
the three possible differences that you might be interested in. If there
are four groups, you would use three indicator variables, but there are
actually six possible comparisons between pairs of means.

Second, when you compute multiple confidence intervals, the overall
confidence level across all the intervals will be less than 95\%. If
each interval has a 5\% chance of being wrong, then if you compute
multiple intervals, you will accumulate a greater chance for error.

There are several modifications for these confidence intervals that try
to insure that the overall confidence level remains at 95\%. Click on
the POST HOC button in the general linear models dialog box to see what
your options are.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.37.gif}}

In this example, the TUKEY option was chosen. Tukey works well when you
are interested in examining differences between all possible pairs of
means. If you wish instead to compare each group to a control group,
then the DUNNETT option works well. Just make sure that your control
group is either the last (that is, largest) value or the first
(smallest) value.

Here is part of the output.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.38.gif}}

There are six rows in this table, but half of them are simply reversals.
For example, the confidence interval for Brown - Blue is (-4.735,
0.423), but this is just the reversal of the confidence interval for
Blue - Brown (-0.423, 4.735) just two rows above it.

At first glance, you may notice an apparent contradiction in these
confidence intervals. There is no statistically significant difference
between Blue and Green, since the confidence interval (-1.171, 3.664)
includes the value of zero. Similarly there is no statistically
significant difference between Green and Brown. But there is a
statistically significant difference between Blue and Brown. How can
this be?

It turns out that the differences between Blue and Green and the
differences between Green and Brown are around 1.3, which well within
the range of sampling error. But the difference between Blue and Brown
is about 2.6, which is beyond the limits of sampling error.

One way to think of this is that the confidence intervals are measuring
closeness rather than equality. Just because Blue is close to Green and
Green is close to Brown does not imply that Blue is close to Brown.

SPSS also produces a list of homogenous subsets.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.39.gif}}

This list shows groups of means which would close enough together to be
considered within the range of sampling error. This list recpas the
findings that we discussed above. Blue and Green form a homogenous
subset because their means are within the range of sampling error. Green
and Blue form a second homogenous subset.

Be cautious about the interpretation of this table when the sample sizes
are not close to the same size. If there are two groups with much
smaller sample sizes and these groups have means at the extremes, they
may make all the other means in between appear to be homogenous, even
though the larger sample sizes for these intermediate means might have
far less sampling error.

\subsubsection{Analysis of multiple
factors}\label{analysis-of-multiple-factors}

When you have more than one factor to consider in an ANOVA model, the
statistics become considerably more complex.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anovaSS01.gif}}

The graph above shows data for a study of swimming times in a 25 meter
pool. This experiment looked at three factors which might influence swim
times:

\begin{itemize}
\tightlist
\item
  Goggles (On = +; Off = -),
\item
  Flippers (On = +; Off = -),
\item
  Tee Shirt (On = +; Off = -).
\end{itemize}

The horizontal axis has eight tick marks corresponding to the eight
possible combinations of goggles, flippers, and shirt. The circles
represent the actual swimming times. The flat side of the arrow
represents what you would predict the time to be ignoring any of the
three factors--19.72, which is the overall mean for all 24 swimming
times. The pointed side of the arrows represent what you would predict
if you knew the value for goggles. Swim times are 0.79 minutes less if
goggles are on (18.93 = 19.72 - 0.79) and 0.79 minutes more if the
goggles are off (20.51 = 19.72 + 0.79). Notice that the improvement in
prediction is very modest. You can quantify the improvement as
SS(goggles) = 24 * 0.79\^{}2 = 14.98. The ANOVA table in SPSS (see
below) produces a slightly smaller value, 14.90, because the
calculations above have a bit of rounding error.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.40.gif}}

Notice that there is a lot of room for improvement. Total variation is
193.76, so a model with goggles in it accounts for only 14.90 / 193.76 =
7.7\% =of the variation.

How much better would the prediction be if we also accounted for the
second factor, flippers?

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anovaSS02.gif}}

The graph above shows the improvement from a model that includes goggles
only (flat end of the arrow) to a model that includes goggles and
flippers (pointed end of the arrow). Notice here how much the predicted
values change. If flippers are on, the predicted values decrease by 2.57
minutes and if flippers are off, the predicted values increase by 2.57
minutes. With two factors, notice that the predictions can equal four
separate values. You can quantify the improvement as SS(flippers
\textbar{} goggles) = 24*2.57\^{}2 = 158.52. The ANOVA table in SPSS
(see below) produces a slightly different value, 158.67, again because
of rounding error.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.41.gif}}

Notice that the model with both goggles and flippers is a much better
model. The variation accounted for by two factors combined is
14.90+158.67 = 173.57 and this represents 173.57 / 193.76 = 89.6\% of
the total variation.

Can we do better by including the third factor, shirt?

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anovaSS03.gif}}

The graph above shows the improvement from a model that includes shirt
and goggles to a model that includes shirt, goggles, and flippers. The
changes are small, but are working towards a slightly better prediction.
Predicted values with a shirt on are 0.69 minutes larger and predicted
values with a shirt off are 0.69 minutes smaller. The size of this
improvement is quantified as SS(shirt \textbar{} goggles, flippers) = 24
* 0.69\^{}2 = 11.43. The table in SPSS has a slightly different value,
11.30, because the calculations above have some rounding error.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.45.gif}}

The model with three factors predicts very well. The three factors
combined account for variation of 14.90 + 158.67 + 11.30 = 184.87, which
is 184.87 / 193.76 = 95.4\% of total variation. This leaves unaccounted
variation of only 193.76 - 184.87 = 8.89.

\subsubsection{Sequential versus partial
SS}\label{sequential-versus-partial-ss}

The calculations shown above involve a sequence of models. The table
below summarizes the changes in this sequence of models:

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.46.gif}}

A single factor model with goggles represent a 14.90 unit
increase\textgreater{} over nothing.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.47.gif}}

A two factor model with goggles and flippers together represent a 158.67
unit improvement over the single factor model.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.48.gif}}

A three factor model with goggles, flippers, and shirt represents an
11.30 unit improvement over the two factor model.

Notice that the increase in SS(Model) is matched by a corresponding
decrease in SS(Error). There is a corresponding decrease in unaccounted
variation whenever your model improves.

Calculating a sequence of increasingly complex models will produce
sequential SS, which is also known as Type I SS. Sequential SS are easy
to understand, but sometimes the sequence of variables is somewhat
arbitrary. Why did you place goggles in the model first and shirt last?
Would a different order (shirt first, then shirt plus goggles, then
shirt plus goggles plus flippers) make more sense?

With this particular data set, it turns out that there is not any
difference, but in other cases, the sequence does indeed change things.
Another approach to ANOVA models is to use partial SS, also known as
Type III SS. Partial SS compares the predictive ability of a model with
all factors to a model with everything except the factor of interest.
This measures the effect of a factor above and beyond all the other
factors in the model. Partial SS answers the question, how much
variation does this factor account for after variation for all the other
factors have been removed.

Here's an example of partial SS calculations:

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.49.gif}}

A two factor model without goggles accounts for 169.97 units of
variation. A model with all three factors accounts for 184.87 units of
variation. This is an improvement of 14.90 units.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.50.gif}}

A two factor model without flippers accounts for 26.20 units of
variation. A model with all three factors accounts for 184.87 units of
variation. This is an improvement of 158.67 units.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.51.gif}}

A two factor model without shirt accounts for 173.57 units of variation.
A model with all three factors accounts for 184.87 units of variation.
This is an improvement of 11.30 units.

Are conclusions do not change at all with the use of partial SS. The
factor, flippers, is the most important variable because it accounts for
most of the variation. With this data set, it doesn't matter whether
flippers comes first, last, or in between. Partial SS are especially
important for complex ANOVA models. This includes models with unbalanced
sample sizes and models with a mix of continuous and categorical
variables.

Here's an example of where the sequence of models is very important. In
a study of breastfeeding, two important categorical factors are delivery
type (C/S vs VAG) and marital status (married vs single). An important
continuous variable is mother's age. The dependent variable is the
duration of breast feeding.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.52.gif}}

When marital status appears first in sequence, it accounts for 640 units
of variation..

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.53.gif}}

When marital status appears last in sequence, it accounts for only 217
units of variation. One possible explanation for this finding is that
there is some overlap between marital status and mother's age. Married
mothers tend to be older than single mothers (see the box plot below).
Thus some of the variation accounted for by marital status could perhaps
be also accounted for by mother's age. Notice that the SS for mother's
age increased from 475 to 787 when it appears in the model before

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.54.gif}}

Partial SS or Type III SS are often thought of as conservative. A factor
gets a piece of the pie only after all the other factors have taken
their piece first. Usually the partial SS are smaller than the
sequential SS, but not always. Notice for example, that the partial SS
for delivery type is 1042, which is bigger than the SS when this factor
enters the model first (962) or second (852).

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.55.gif}}

\subsubsection{Analysis of interactions}\label{analysis-of-interactions}

When you have multiple factors in an ANOVA model, you may wish to
examine interactions. An interaction is a combination of two or more
factors where the joint effect of these factors is not equal to the sum
of the individual effects.

Here is an ANOVA model with two factors and an interaction. The effect
of the interaction is not quite, but close to statistical significance.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.42.gif}}

What does this interaction mean. Let's look at a plot showing the time
without goggles as red circles and the time with goggles as black plus
signs. The left side of the graph is the times without flippers and the
right side of the graph is the times with flippers. A red dashed line
connects the average times without goggles and a black dotted line
connects the average times with goggles.

The example shown her is an antagonistic interaction.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.43.gif}}

A few things are obvious right off the bat. First the red dashed line is
higher than the black dotted line. This is not a surprise. We know that
wearing goggles improves your time. Second, both lines have a negative
slope. This again, is not a surprise as wearing flippers also improves
your time. Third, these lines are not parallel. Flippers give you more
of an improvement when you don't also have the advantage of goggles. The
converse is true as well. The gap between the two lines shrinks, meaning
that the edge that goggles gives you is more prominent when you don't
also have the advantage of wearing flippers.

There are two types of interactions: synergistic versus antagonistic. A
synergistic interaction is one where the combination of two factors
gives you more than you would expect from simply adding the effect of
the first and second factor. You could call this a super-additive
interaction.

An antagonistic interaction is one where the combination of two fractos
gives you less than you would expect from simply adding the individual
effects. You could call this a sub-additive interaction.

You can also look at the graph with the flippers and goggles reversing
roles.

\pandocbounded{\includegraphics[keepaspectratio]{index_files/mediabag/anova.44.gif}}

Normally it is not necessary to look at things both ways. They will
normally lead to the same general interpretation.

\bookmarksetup{startatroot}

\chapter{Running a survival data
analysis}\label{running-a-survival-data-analysis}

This chapter is based on a web page I wrote in 2002.

\section{Step 1: Plot Kaplan-Meier curves for each
group}\label{step-1-plot-kaplan-meier-curves-for-each-group}

Examine raw probabilities using crosstabs

Add text.

\section{Step 2: Compute a simple surivival
model}\label{step-2-compute-a-simple-surivival-model}

Add text.

\section{Step 3: Compute an adjusted survival
model}\label{step-3-compute-an-adjusted-survival-model}

Add text.

\section{The fly in the ointment: time-varying
covariates}\label{the-fly-in-the-ointment-time-varying-covariates}

Add text.

\section{Bibliography}\label{bibliography-13}

Simon SD. Steps in a typical survival data analysis. PMean blog,
2002-10-11. Available in
\href{http://pmean.com/posts/steps-in-survival-analysis/}{html format}.

\bookmarksetup{startatroot}

\chapter{Running a non-linear regression
analysis}\label{running-a-non-linear-regression-analysis}

This chapter is based on a web page I wrote in 2004.

\section{Step 1: Plot your data}\label{step-1-plot-your-data-2}

Look for interactions

\section{Step 2: Explore your
function}\label{step-2-explore-your-function}

Add text.

\section{Step 3: Fit your model}\label{step-3-fit-your-model}

Add text.

\section{The fly in the ointment: ill-conditioned
models}\label{the-fly-in-the-ointment-ill-conditioned-models}

Add text.

\section{Bibliography}\label{bibliography-14}

Simon SD. S-shaped curves. PMean blog, 2004-02-12. Available in
\href{http://pmean.com/posts/fitting-s-shaped-curves/}{html format}.

\bookmarksetup{startatroot}

\chapter{Running a systematic
overview}\label{running-a-systematic-overview}

This chapter is based on a webpage I wrote in 2016.

\section{Step 1: Write a protocol}\label{step-1-write-a-protocol}

Look for interactions

\section{Step 2: Collect references}\label{step-2-collect-references}

Add text.

\section{Step 3: Extract information}\label{step-3-extract-information}

Add text.

\section{The fly in the ointment: extreme
heterogeneity}\label{the-fly-in-the-ointment-extreme-heterogeneity}

Add text.

\section{Bibliography}\label{bibliography-15}

Simon SD. So you're thinking about a systematic overview. PMean blog,
2016-06-17. Available in
\href{http://pmean.com/posts/systematic-overview/}{html format}

\bookmarksetup{startatroot}

\chapter{Running a focus group}\label{running-a-focus-group}

\emph{It's really hard to design products by focus groups. A lot of
times, people don't know what they want until you show it to them.}
Steve Jobs as quoted in

This chapter is based on a blog post I wrote in 2004 and slides from a
course I have taught on Clinical Research Methodology.

\section{Step 1: Plan your logistics}\label{step-1-plan-your-logistics}

Logistics sounds so mundane .

\section{Step 1: Select a theoretical
framework}\label{step-1-select-a-theoretical-framework}

phenomenology topic\_10: ``Grounded theory'' topic\_11: ``Ethnography''
topic\_12: ``The case sudy'' topic\_13: ``Narrative''

Look for interactions

\section{Step 2: Write probe
questions}\label{step-2-write-probe-questions}

Add text.

\section{Step 3: Revise your questions as you learn from each focus
group}\label{step-3-revise-your-questions-as-you-learn-from-each-focus-group}

Add text.

\section{The fly in the ointment:uneven
participation}\label{the-fly-in-the-ointmentuneven-participation}

Add text.

\section{Bibliography}\label{bibliography-16}

Simon SD. Focus groups and qualitative research. Pmean blog, 2004-04-13.
Available in \href{http://pmean.com/posts/focus-groups-are-great/}{html
format}

Simon SD. simon-5510-10-slides. PMean github repository. Available in
\href{https://github.com/pmean/classes/blob/master/clinical-research-methodology/10/results/simon-5510-10-slides.pdf}{pdf
format}.

Tausch AP, Menold N. Methodological Aspects of Focus Groups in Health
Research: Results of Qualitative Interviews With Focus Group Moderators.
Glob Qual Nurs Res. 2016 Mar 14;3:2333393616630466. doi:
{[}10.1177/2333393616630466{]}{[}ref17-tausch-2016{]}.

Wong LP. Focus group discussion: a tool for health and medical research.
Singapore Med J. 2008 Mar;49(3):256-60; quiz 261. PMID: 18363011.
https://smj.sma.org.sg/4903/4903me1.pdf

Lander, J., Wallraf, S., Pieper, D. et al.~Recruiting participants for
focus groups in health research: a meta-research study. BMC Med Res
Methodol 25, 9 (2025). doi: {[}10.1186/s12874-025-02464-x{]}{[}ref17{]}
https://doi.org/10.1186/s12874-025-02464-x

\section{Material from Clinical Research Methodology
class}\label{material-from-clinical-research-methodology-class}

\section{\texorpdfstring{\texttt{r\ section}, Running focus
groups}{r section, Running focus groups}}\label{r-section-running-focus-groups}

\begin{itemize}
\tightlist
\item
  Two person job
\item
  Facilitator

  \begin{itemize}
  \tightlist
  \item
    Asks questions
  \item
    Guide discussion, but stays neutral
  \end{itemize}
\item
  Recorder

  \begin{itemize}
  \tightlist
  \item
    Runs the tape recorder
  \item
    Keeps written notes
  \end{itemize}
\item
  Debriefing session
\end{itemize}

If you decide to collect data in a focus group, you need a second
person. You could do it by yourself, but you are asking for trouble. One
of you takes the role of the facilitator and one takes the role of the
recorder.

The facilitator asks a series of prepared questions. Your role is to
guide the discussion while still keeping neutral. This means that you
intervene if the group is getting off target or if one person is
dominating the discussion. You should prepare some brief prompts to get
your participants to elaborate or to draw in other participants.

The recorder doesn't say anything after the introductions, but runs the
recording device and take notes. The notes serve several purposes.
First, they serve as a backup if your recording fails. Second, they note
any significant non-verbal information such as gestures and body
language. Third, the notes help to identify who is speaking when. A
seating diagram is helpful for this. Note that not all focus groups
track who is speaking.

After the session is complete, the two of you sit down and talk about
how things went.

\section{\texorpdfstring{\texttt{r\ section}, Structure of a focus
group}{r section, Structure of a focus group}}\label{r-section-structure-of-a-focus-group}

\begin{itemize}
\tightlist
\item
  Six to ten participants
\item
  Multiple groups

  \begin{itemize}
  \tightlist
  \item
    Stop when you achieve saturation
  \end{itemize}
\item
  Sixty to ninety minutes
\item
  Ten questions, semi-structured interview
\end{itemize}

The size of a focus group can vary, but I've seen recommendations of six
to ten people.

What the research community does agree on is that you need to plan for
more than one group. The consistency of responses from one group to the
next will tell you if you have reached saturation.

Saturation is evidence that no new themes or ideas have emerged from
your groups. Almost all assessments of whether saturation has been
achieved are qualitative and subjective.

The concept of saturation makes it difficult for you to plan a budget,
but keep in mind that you cannot even begin to assess saturation until
you've run your second focus group.

Other common recommendations are to keep each session short, 60 to 90
minutes, and to have no more than ten questions. Your questions should
follow a semi-structured format, which I'll talk about in the context of
interviewing.

Getting information from a group is a double-edged sword. Often in a
focus group, one participant will build on the comments of another and
provide a perspective that you may have missed in a single person
interview. At other times, however, one person may stifle the feedback
from another. A good focus group leader will recognize this and work to
insure that everyone participates fully. It's easy to say this in
theory, but in practice, it can be difficult.

\section{\texorpdfstring{\texttt{r\ section},
Interview}{r section, Interview}}\label{r-section-interview}

\begin{itemize}
\tightlist
\item
  Administration

  \begin{itemize}
  \tightlist
  \item
    Telephone
  \item
    Face-to-face
  \end{itemize}
\item
  Format

  \begin{itemize}
  \tightlist
  \item
    Unstructured
  \item
    Semi-structured
  \item
    Structured
  \end{itemize}
\end{itemize}

An interview is direct communication between the researcher and the
subject. You can set up the interview on the telephone or conduct a
face-to-face interview. The obvious advantage of a telephone interview
is that it is fast and does not involve travel of either party.

A face-to-face interview takes more effort, but can sometimes help with
building a sense of rapport and trust.

Interviews have three formats, unstructured, semi-structured, or
structured.

In an unstructured interview, you go in with a general idea of what to
discuss, but no specific questions. The general direction of the
interview will determine what questions to ask next. An unstructured
format is rarely used in research because it makes you work impossible
to replicate.

A semi-structured interview has a planned structure that includes a list
of questions to ask. These questions are typically open ended, to allow
the patient to bring up issues that the researcher may not have been
aware of. Most semi-structured interviews have a series of probe
questions that are intended to prompt the research subject to elaborate
further on a topic of interest.

A structured interview has a fixed set of questions that are asked in a
consistent order with no major deviations. There are no prompts to get
your patients to elaborate, but the interviewer can try to clarify any
ambiguous or clearly invalid responses.

\section{\texorpdfstring{\texttt{r\ section}, Example of structured and
unstructured
interviews}{r section, Example of structured and unstructured interviews}}\label{r-section-example-of-structured-and-unstructured-interviews}

\pandocbounded{\includegraphics[keepaspectratio]{chapters/../images/interview-questions.png}}

Here's an example of two interviews. The first is a structured interview
with four yes/no questions.

``Before you were 17 years of age (Each question had answer choices of
``Yes'' or ``No)''

a parent or guardian ever do something to you on purpose (for example,
hit or punch or cut you, or push you down) that made you bleed or gave
you bruises or scratches.

Did, or that broke bones or teeth?''

Did either of your parents or guardians get so mad at you that they hurt
you physically?

Did either of your parents or guardians use physical punishment for
discipline?

The second interview is described as unstructured. I would call it
semi-structured, but that is a nitpick. The questions were

How do your parents or guardians discipline you?

Do they ever physically hit you?

How do they punish you?

Further probing was done depending on the responses to the questions:
having been hit, punched, kicked, or otherwise struck or pushed down;
cut, bruised, made to bleed, scratched, having broken bones, broken
teeth, or having been hurt physically

The questions in this structured interview are close ended. This is
quite common, but you can also have a structured interview with open
ended questions. For the semi-structured or unstructured interview,
however, the questions must be open ended so that you can probe for more
information.

The article that these interview questions came from noted that the
unstructured interview was far more likely to uncover reports of abuse
than the structured interview.

Image source: Diaz 2017 (see the reading list for full details).

\bookmarksetup{startatroot}

\chapter{Writing a literature review}\label{writing-a-literature-review}

This material is based loosely on my week 3 lectures in Clinical
Research Methodology. Also look at my blog post on an introduction
section. An introduction is not quite the same thing as a literature
review, but the guidance might still be helpful.

Let's start by defining what a literature review and what it is not. A
nice definition appears in Gliner 2016.

\emph{``An interpretation of a selection of documents (published or
unpublished) on a specific topic that involves summarization, analysis,
evaluation, and synthesis of the documents.''}

Let's parse some of those words. It is a \textbf{summarization}. You
take a group of research article that are often five or ten pages long
and convert each one into a sentence or two.

It requires \textbf{analysis}. You have to gain an understanding of the
true meaning hiding inside each paper.

It needs \textbf{evaluation}. To what extent are the claims in each
paper valid.

It involves \textbf{synthesis}. You have to combine these studies into a
cohesive structure.

What all of this means is that you have to live and breath these
studies. You can't summarize, analyze, evaluate, or synthesize with only
a superficial understanding of these papers.

Don't confuse a literature review with an \textbf{annotated
bibliography}. An annotated bibliography involves summarization,
analysis, and evaluation, but it lacks synthesis. Each study stands
alone with no sense of structure or flow. Make sure when you write your
literature review that it isn't a laundry list of studies.

Also don't confuse a literature review with a \textbf{systematic
overview}. A systematic overview conducts an exhaustive search of all
papers that address a narrowly focused clinical question, and combines
the results (sometimes quantitatively through a meta-analytic approach)
to produce the best answer to that clinical question. A literature
provides a more general overview and does not need to cite every
available source.

You can produce a literature review as a stand-alone paper, but this
chapter will focus on writing a literature review that is part of a
larger research paper. In this setting the literature review provides
the background that any reader needs to know before examining the rest
of your research. You will summarize the details of your research as in
a methods section (our next chapter). Keep in mind as you write your
literature review that it will need to lead in to the next section of
your paper, the methods section. Writing the methods section is a topic
for the next chapter.

There is a fairly universal demand that your literature review rely only
on \textbf{primary sources}. Primary sources are the sources that
actually produced the findings. Do not, the advice goes, rely on
secondary sources, sources that synthesize the work of others.

The epitome of secondary sources is Wikipedia. I know that a lot of
people hate Wikipedia. Just for the record, I think that Wikipedia is a
great starting point. The language is accessible and they try to list a
few key references. Don't cite that Wikipedia page, but you can peek at
it during the early phases of writing your literature review.

\section{Step 1: Document your
searches}\label{step-1-document-your-searches}

Finding resources for your literature review is a challenge. If you can
find a librarian who is willing to help, great! Librarians are experts
in finding things.

You might start your hunt with an Internet search engine like Google, a
bibliographic database like Pubmed, or some other approach.

The challenge will be producing a sensitive and specific set of results.

A sensitive search is one that has very few false negatives. It captures
all of the relevant resources, leaving no stone unturned. That sounds
good but a sensitive search comes at a price. In order to capture
everything, you may produce a list that is too long to process
effectively.

A specific search is one that has very few false positive. Almost
everything you see is golden. Again, this sounds good. A specific search
produces a short list and a short list means less work. Yes, but maybe
you left out something that is really really good. Finding the right
balance is tricky, but it makes sense to have a short specific list,
especially when you are just getting started.

First, write down the keywords that you used in every search engine and
in every bibliographic database. Note which searches were too sensitive.
You won't be able to tell which searches were too specific, but do
consider a broader search if you find a list that just seems
\textbf{too} short.

Review the list before each new search and try to make sure that you are
addressing any major gaps in your literature review.

\section{Step 2: Stash your results}\label{step-2-stash-your-results}

Librarians excel in stashing information in places that are easy to
retrieve. So lean on the help you can get, if you have a librarian you
can work with.

Stashing is important, but easily neglected. You don't want to find an
interesting resource through a search engine or a bibliographic
database, say to yourself, ``Oooh! That is an interesting resource!''
and then file it away in the back of your brain. A week or a month
later, you will want to go to the back of your brain and it won't be
there. Your memory may be good, but your forgetery is even better.

Where do you write down your ``Oooh!'' articles? The old school way is
with index cards. I know, I know. This is the digital era and everything
lives on computerized devices. But for some of you, the old ways are
just fine.

Index cards allow you to flip through references, classifying them into
related piles and sorting them in different orders. Write a note on your
cards about which searches produced which references. This will allow
you to re-visit the searches that can fill in the thinner parts of your
literature review.

Another popular approach is to store your references in a spreadsheet.
Attach tags that identify where you expect each reference to sit in your
literature review. Sorting by the tags will place your references into
the correct piles. Again, take note of which searches produced which
references.

A third approach is to invest in a bibliographic software. Some of it is
free, but you still have an investment in time learning the software.
There are many good choices for bibliographic software and they have
many time saving features. When you find an interesting paper, the
bibliographic software imports the reference, complete with the authors,
journal, year of publication, and even the abstract.

In your software, note the source of your search and add tags. With good
tags, the bibliographic software can arrange your references in piles.

While the index cards and spreadsheets are fine choices, you may find
that investing the time in a full-featured bibliographic system will
save you time in the long run. Perhaps not in the stashing of results,
but you will really see a good payoff when your prepare citations and a
bibliography.

\section{Step 3: Decide on an organizing
principle}\label{step-3-decide-on-an-organizing-principle}

A literature review is not a random, unordered jumble of papers. It has
to flow. To get this flow, you need an organizing principle. The
principle will help you decide what papers do you cite early and what
papers do you cite late.

There are several approaches that you sould consider. The first and
simplest is a chronological approach. Talk about the earliest references
first and the latest references last. The chronological approach may
make sense if diagnosis and treatments of a particular medical condition
have changed dramatically over time. Do be careful, though. A literature
review that goes ``First\ldots, Next\ldots, Then\ldots{}'' can sometime
come across as dull.

Another approach is thematic. identify themese and present all the
references that are associated with the first theme, then those
associated with the second theme, and so forth.

The possible themes that you might consider are too many to mention and
most themes may not fit the body of research that you are trying to
summarize in your literature review. But try some of these themes if
they look like they might fit.

Start with consensus (questions where everyone agrees on the correct
answer), then list disagreements (questions with debates among competing
answers), and end with the unknown (questions with no answers yet).

Or say what the problem is, say what has already been done, and say what
needs to be done.

Or offer a thesis and group your references into two sections, articles
that are supportive of your thesis and articles that are not supportive.

You might organize your articles into groups sharing common
methodologies. In a study of mitigation of home exposures that might
exacerbate asthma, the studies might be grouped by those that study a
physical intervention (like improved ventilation) and by those that
study a chemical intervention (spraying for dust mites).

In a review of behavioral change, you might organize articles by the
different theories of change (Lewin, Rogers, or Spradley) that they rely
on.

Some studies of child welfare management might utilize the attachment
theory while others might use crisis intervention theory or social
construction theory.

It's really hard to give examples here because there are so many
different thematic organizations that you can choose from.

The approach I like best is to move from the general to the specific.
There are several directions you can go, but one way would be talking
about the disease, talking about a particular treatment of the disease,
and then talking about that treatment in a particular subpopulation. Of
course, talking about the disease, then a subpopulation and then a
treatment within that subpopulation also works.

You start with the general because that is what your reader is most
likely to be familiar with. As you make things more specific, you draw
them in to the need for your research.

Here's an example of moving from general to specific in a publication I
am a co-author on. I can't take credit for the excellent organization.
The first author, Janette Berkley-Patton, is the one who did such a fine
job.

Her first paragraph in the literature review starts out with a very
broad perspective.

\begin{quote}
``African Americans represent nearly 45\% of new HIV cases each year
(1--2).''
\end{quote}

Here second paragraph narrows things down.

\begin{quote}
``The Black Church is a powerful institution with a history of
mobilizing African American communities for social change (5)\ldots{}''
\end{quote}

The third paragraph tightens things up even more.

\begin{quote}
``Studies suggest many African American faith leaders are willing to
provide HIV education and testing for their church/community members
(14--17)\ldots{}''
\end{quote}

Berkley-Patton et al 2016.

You can also help the flow by using transitional words. A long list,
study after study can easily lead the reader to feel lost in all the
details. Place each study in context relative to the previously
mentioned. If the study is providing further support to the results of
the previous study, emphasize this with words like ``also'' or ``in
addition''. If the study contrasts or contradicts the previous study,
emphasize this using words like ``in contrast'' or ``on the other
hand''. This is a little thing, but it does help.

THe final transition should be a summary of your work. All the previous
references should build to a climax, a climax that asserts how your
research is the next logical step in the series of references that you
have summarized.

\section{The fly in the ointment: too many/too few
references}\label{the-fly-in-the-ointment-too-manytoo-few-references}

Add text.

\section{Bibliography}\label{bibliography-17}

Berkley-Patton J, Thompson CB, Moore E, Hawes S, Simon S, Goggin K,
Martinez D, Berman M, Booker A. An HIV Testing Intervention in African
American Churches: Pilot Study Findings. Annals of Behavioral Medicine.
2016; 50(3):480-5.

Gabriel D. How to write a literature review. Blog post 2017-08-21.
Available in
\href{https://deborahgabriel.com/2017/08/21/how-to-write-a-literature-review/}{html
format}.

Gliner JA, Morgan GA, Leech NL. Research Methods in Applied Settings: An
Integrated Approach to Design and Analysis, Third Edition. Routledge
2016.

Simon SD. Writing the introduction section of a research thesis or
dissertation. Pmean blog, 2019-03-29. Available in
\href{http://pmean.com/posts/introduction-section/}{html format}.

Simon SD. What is a literature review. Github repository. Available in
\href{https://github.com/pmean/classes/blob/master/clinical-research-methodology/03/results/simon-5510-03-slides.html}{html
format}.

\bookmarksetup{startatroot}

\chapter{Writing a methods section}\label{writing-a-methods-section}

This chapter is based on web pages I wrote in 2011 and 2019.

When I write a methods section, I say that any moron can do this
research and then prove it by doing it myself.

That's a bad joke, and the methods section is not written for morons. It
is written for two well-educated audiences: appraisers (readers who want
to make a critical appraisal of your work) and replicators (readers who
want to replicate your work).

The appraisers want to know if your research meets acceptable standards.
For these readers you want to brag about the things you did well. At the
same time, be honest about any compromises that you had to make. Don't
ask your reader to read between the lines. If you couldn't use blinding,
say this. Trying to hide things won't work. Most critical appraisals
will assume that no news is bad news. They will infer that only did you
do something bad, but you were too naive to even recognize that it was a
bad thing.That's okay, but your failure to mention the bad news will
brand you as naive.

The replicators ant to understand exactly what you did and how you did
it because they want to do something just like you did, possibly with
some extensions and improvements. For this audience, you need more
details, but not every last detail. Remember that anyone who wants to do
something like what you did is reasonably well educated. Assume that
they can do the routine stuff, and only document things that are tricky.
Include references, if needed.

There is going to be a tension between making the appraisers happy and
making the replicators happy. One thing that will help is that you can
make some pretty strong assumptions about the two types of readers. If
one of your methods is assessing a rectal temperature, skip the details.
The replicators already know how to do this and the appraisers don't
want to know how to do this.

There's lots of guidance on how to organize your subsections inside
methods.

Richard Kallet has a nice publication in Respiratory Care.

\begin{itemize}
\tightlist
\item
  Subjects,
\item
  Ethical considerations,
\item
  Preparations,
\item
  Protocol design,
\item
  Measurements and calculations,
\item
  Data analysis
\end{itemize}

Elena Kallestinova's publication in the Yale Journal of Biology and
Medicine provides a structure through a series of questions.

\begin{itemize}
\tightlist
\item
  What materials did you use?
\item
  Who were the subjects of your study?
\item
  What was the design of your research?
\item
  What procedure did you follow?
\end{itemize}

The International Committee of Medical Journal Editors have published a
general guide to writing a paper with a fair amount of detail about what
goes in the methods section.

\begin{itemize}
\tightlist
\item
  Selection and description of participants,
\item
  Technical information,
\item
  Statistics.
\end{itemize}

Asghar Ghasemi and others have a nice publication in the International
Journal of Endocrinology and Metabolism with only two major sections
(but several subsections in each).

\begin{itemize}
\tightlist
\item
  Materials (Chemical, Experimental materials, Experimental animals,
  Human subjects),
\item
  Methods (Study design, Measurements/assessments, Statistical analyses)
\end{itemize}

Are you confused yet? Don't despair. The fact that there are so many
different standards out there means that you have a lot of latitude in
how to structure your methods section. The best advice I can offer is to
read a half dozen articles or theses and take notes about what these
writers did. Use these suggestions more to assure that you have included
all the relevant details, but don't follow any structure mindlessly.
Don't include a subsection on chemicals if your research didn't use any
chemicals.

My recommendation is to describe two things, the who and the how, and
then lay out a statistical analysis plan. One important dividing line is
that anything that you learn after you start recruiting patients belongs
in the results section. The methods section should only include what you
knew at the start of the study. One possible exception is a description
of how many patients were lost along the way. This is often done as a
flow chart, as described below.

\section{Step 1: Talk about who}\label{step-1-talk-about-who}

Exactly who is in your study? This description will allow appraisers to
answer a key Evidence-Based-Medicine question: how similar are my
patients to those in your study. A demographic profile actually belongs
as the very first table in your results section, but there are other
important details that you should document in your methods section.

Tell us where you found your patients. Did they visit your clinic or did
they respond to an advertisement? This is an important distinction.
Patients who respond to an advertisement are going to have a different
set of motives, especially if your ad includes a monetary incentive.
This can influence the generalizability of your results.

Tell us when you found your patients. A range of dates will help your
appraisers to decide if your results are stale, meaning that they were
treated during a time when things were different. Explain if the
patients were recruited prospectively or from retrospective records.

Not everyone gets in. Tell us, in detail, any inclusion and exclusion
criteria. Document any special efforts that you take to insure
representativeness. Be honest about any limitations (both here and in
your discussion section) to representativeness that might make it more
difficult to extrapolate your results to new patients.

You are going to lose patients during the process, either through
deliberate efforts on your end (your exclusion critieria), deliberate
efforts on their end (withdrawal from the study), or logistical problems
(missed apointments, broken machinery). Document these using a flow
chart. The CONSORT (Consolidated Standards of Reporting Trials) working
group has recommended format for this chart.

Most (but not all) clinical research requires review for ethical and/or
privacy concerns. Document any approvals (for example, from
Institutional Review Boards) that you obtained before starting your
research. If your protocol was published in a clinical trial registry
(like clinicaltrials.gov), provide those details as well.

\section{Step 2: Talk about how}\label{step-2-talk-about-how}

How you do your research can fall into three general categories:
materials, procedures, and measures.

If you use any exotic supplies or chemicals, describe them here. List
the company where you procured them if they are not commonly available.
By exotic, I mean not in general use, and/or hard to find. Don't
document materials if they are not exotic. Ringers solution is not
exotic.

Documentation of procedures is similar to documentation of materials.
You only need to document the non-routine procedures. This might involve
the details on running complex equipment or the steps in an extensive
laboratory method. If these procedures are described in a peer-reviewed
publication, you might want to include that reference here. In general,
a basic procedure does not need documentation, but there are exceptions.
You might take the time to document an assessment of blood pressure if
it was done on a leg rather than an arm.

Document some (but not necessarily all) of your measures Don't describe
every single measurement, just those that are important. This, I admit,
is a judgment call.

What are the important measures? Outcome measurements are important. An
outcome measurement is one that helps you assess safety or efficacy.

Independent variables are important. These are measures that you are
interested in examining how they influence the outcome.

These variables could represent a new intervention that you give to some
of your patients versus a standard of care or a placebo, There are, sad
to say, more than a few interventions that were tested and found out to
do more harm than good.

Independent variables might instead represent exposures. An exposure is
not under your control. Exposures could be helpful or could be harmful,
but they always represent variables that you, the researcher, do not
wish to control or variables that you cannot control.

Covariates are important. Covariates are variables that you are not
interested in examining directly but which you must account for in a
proper study. Often, these are variables that already have a well
established connection to the outcome and failure to account for them
would sink the credibility of your research.

No cancer study, no matter what the treatment or exposure, would fail to
ask for information about smoking. Those cigarettes don't just cause
lung cander. They cause kidney cancer, liver cancer, that funny thing
hanging in the back of your throat cancer. Failure to control for or
adjust for smoking is a fatal flaw.

Likewise, any study in neonatology has to account for gestational age
and birthweight. Babies that arrive early and arrive tiny have so many
more problems than the later, bigger babies. Again, failure to account
for these covariates would be a fatal flaw.

Intermediate measurements are sometimes important. Intermediate
measurements are variables which are possibly influenced by your
independent variables and which, in turn, might possibly influence the
outcome. Often these variables help you to understand how a treatment
worked or why it failed.

There might be other variables, such as those that you collect during
the initial interview to see if a patient qualifies for your study.
These probably do not need to be documented.

You should present information about the validity/reliability of any
variable that warrants it. Definitely include information about
validity/reliability for key outcome measures, if they are available.
This information adds credibility to your study. For other variables,
this is a judgement call. Variables that require subject assessment,
either by the treating physician or by the patients themselves, can
often benefit from an assessment of validity/reliability.

For all of these measures, be sure to mention anything special that you
did to improve the quality of those measures. you might make
measurements in a blinded fashion, take repeated measurements, or get
measurments from two or more observers. All of these can help and are
worth bragging about.

Some studies might require you to document dozens, and sometimes even
hundreds of measures. Consider using a table for some or all of these
measures.

\section{Step 3: Talk about your analysis
plan}\label{step-3-talk-about-your-analysis-plan}

Analysis. Describe how you plan to analyze your data. Most analyses
start with some simple descriptive statistics: means and standard
deviations for continuous variables and percentages for categorical
variables.

Provide your research hypothesis in this section, and state whether it
is one-sided or two-sided. One-sided hypotheses require a brief
justification, along with an assurance that the direction of the
hypothesis was selected prior to data collection. Mention the
statistical test that you plan to use. If you are running more than one
test, explain what measures you will use to control the Type I error
rate. In some settings, it may be acceptable to not make adjustments for
multiple tests, but you should state this explicitly.

You do not need to provide references for simple and commonly used
statistics, like a t-test, linear or logistic regression, or analysis of
variance. More complex procedures should include a reference. If you are
referencing a book, remember that a page or page ranges are needed.

You need to define how you will handle missing values and dropouts. If
you plan to exclude extreme values (outliers) from your data set, give
an objective rule here.

Specify what statistical software you plan to use for your analysis
(e.g., SPSS, SAS, or R) and be sure to include the version number. State
any special libraries or macros that you used within your statistical
software system. If your software is relatively uncommon, be sure to
include a reference that explains how the software works and where you
can obtain it.

You also need to justify your sample size, and this usually fits best in
the analysis section. If the goals of your research are qualitative,
then the sample size justification can also be qualitative.

\section{The fly in the ointment: when your who is a
what}\label{the-fly-in-the-ointment-when-your-who-is-a-what}

In clinical research, the unit of analysis is almost always an
individual patient. Sometimes the unit of analysis might be a caregiver
instead, but this changes very little in how you write your methods
section. A problem occurs, however, when you are studying other than a
patient or caregiver. The environment that you are a part of, where you
live and where you work, can play such an important role in your health.
How do you write a methods section when you are studying an environment,
like a home or workplace.

Certain considerations in your methods section disappear. Houses, for
example, do not need to sign an informed consent form. You need
permission from the home owners, of course, but this is not the same
thing. Measurement of weather and/or pollutants do not raise privacy
concerns.

In place of these things, consider beefing up the details on materials
and methods. Careful assessment of environments require a great deal of
rigor. These details are critical for those replicators who want to do
similar work.

Some other details still apply. A house can meet certain inclusion and
exclusion criteria. It has a variety of measures that you need to
document. The analysis will often use the same statistical tests that
you use with a study of patients.

\section{Bibliography}\label{bibliography-18}

About ClinicalTrials.gov. Available in
\href{https://clinicaltrials.gov/about-site/about-ctg}{html format}.

Ghasemi A, Bahadoran Z, Zadeh-Vakili A, Montazeri SA, Hosseinpanah F.
The Principles of Biomedical Scientific Writing: Materials and Methods.
Int J Endocrinol Metab. 2019 Jan 28;17(1):e88155. doi:
\href{https://doi.org/10.5812/ijem.88155}{10.5812/ijem.88155}.

Hopewell S, Chan AW, Collins GS, HrÃ³bjartsson A, Moher D, Schulz KF,
Tunn R, Aggarwal R, Berkwits M, Berlin JA, Bhandari N, Butcher NJ,
Campbell MK, Chidebe RCW, Elbourne D, Farmer A, Fergusson DA, Golub RM,
Goodman SN, Hoffmann TC, Ioannidis JPA, Kahan BC, Knowles RL, Lamb SE,
Lewis S, Loder E, Offringa M, Ravaud P, Richards DP, Rockhold FW,
Schriger DL, Siegried NL, Staniszewska S, Taylor RS, Thabane L,
Torgerson D, Vohra S, White IR, Boutron I. CONSORT 2025 statement:
updated guideline for reporting randomised trials. PLoS Med. 2025;
22(4): e1004587. PMID: {[}40228477{]}{[}ref19-hoepwell-2025{]}

International Committee of Medical Journal Editors. Preparing a
Manuscript for Submission to a Medical Journal. Available in
\href{https://icmje.org/recommendations/browse/manuscript-preparation/preparing-for-submission.html}{html
format}

Kallestinova ED. How to write your first research paper. Yale J Biol
Med. 2011 Sep;84(3):181-90. PMID:
{[}21966034{]}{[}ref19-kallestinova-2011{]}

Kallet RH. How to write the methods section of a research paper.
Respiratory Care. 2004 Oct;49(10):1229-32. PMID:
\href{https://pubmed.ncbi.nlm.nih.gov/15447808/}{15447808}.

Simon SD. Writing the methods section of your grant, Pmean blog,
2011-04-26. Available in {[}html format{]}{[}ref19-simon-2011{]}.

Simon SD. Writing the methods section of a research paper, Pmean blog,
2019-04-25. Available in
\href{http://pmean.com/posts/writing-methods-section/}{html format}

\bookmarksetup{startatroot}

\chapter{Writing a results section}\label{writing-a-results-section}

\section{Step 1:}\label{step-1}

Add text.

\section{Step 2:}\label{step-2}

Add text.

\section{Step 3:}\label{step-3}

Add text.

\section{The fly in the ointment:}\label{the-fly-in-the-ointment-5}

Add text.

\section{Bibliography}\label{bibliography-19}

Bahadoran Z, Mirmiran P, Zadeh-Vakili A, Hosseinpanah F, Ghasemi A. The
Principles of Biomedical Scientific Writing: Results. Int J Endocrinol
Metab. 2019 Apr 24;17(2):e92113. doi:
{[}10.5812/ijem.92113{]}{[}ref20-bahadoran-2019{]}. PMID: 31372173;
PMCID: PMC6635678.

\bookmarksetup{startatroot}

\chapter{Writing a discussion
section}\label{writing-a-discussion-section}

This chapter is based on \textless{}\textgreater. Also refer to
\href{http://www.pmean.com/10/Contents.html}{Tentative table of
contents}.

\emph{One of the naturalists had argued that On the Origin of Species
was too theoretical, that Darwin should have just ``put his facts before
us and let them rest.'' In response, Darwin reflected that science, to
be of any service, required more than list making; it needed larger
ideas that could make sense of piles of data. Otherwise, Darwin said, a
geologist ``might as well go into a gravel-pit and count the pebbles and
describe the colours.'' Data without generalizations are useless; facts
without explanatory principles are meaningless.} Michael Shermer, Why
Darwin Matters. The Case Against Intelligent Design. (page 1).

The discussion section of a research paper is typically the last part of
the paper that you will write, because it draws on information from the
literature review, the methods section, and the results section. It is
not a rehash of any of these sections, but rather a synthesis.

Also keep in mind that most of your readers will know less about your
research area than you do. If you leave the true significance of your
research unstated out of a sense of false modesty, your readers will
likely miss your point.

If you are stuck on writing a discussion section, here are some steps
you can take to get going again.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compare/contrast your results to previous results.
\item
  List the strengths and limitations of your study.
\item
  Advocate changes (or support the status quo)
\item
  Suggest areas for further research.
\end{enumerate}

\section{Step 1: Compare/contrast your results to previous
results.}\label{step-1-comparecontrast-your-results-to-previous-results.}

The literature review your wrote was your chance to lay out what was
known before you started your research. Your results section was your
chance to lay out what you found in your research. In the discussion
section, you need to combine information from both sections.

Did any of your results support what was previously done? That's great.
Brag about it! We now know certain things with much greater confidence
because your work supported and strengthened information and knowledge
in your area of work.

Did any of your results contradict what was previously done? That's
great. Brag about it! Maybe your research is correct, maybe their
research is correct. Maybe both are correct.

If you think your research is correct, explain what was different about
what you did. Speculate a bit. Did your larger sample size find things
that earlier small studies could not? Did you measure things more
carefully? Did you measure things that no one else had measured before?
have larger sample size that led to

The discussion section is also the section for speculation. Not wild
unsupported speculation, of course, but reasonable extrapolations beyond
the strict bounds of your data. If your data calls into question a
proposed mechanism of action, for example, you can suggest an
alternative mechanism. If your proposed intervention did not work as
intended, you can speculate on what changes in your intervention might
have led to a different outcome.

\section{Step 2: List the strengths and limitations of your
study.}\label{step-2-list-the-strengths-and-limitations-of-your-study.}

The discussion section is your chance to answer the ``so what'' question
about your work. You need to place your work in the context of previous
research and discuss the persuasiveness of your findings. Don't be shy
here. If your research is a lot better than any previous work, tell your
readers this. Likewise, tell your readers if you've filled an important
knowledge gap or if you've produced novel insights. In other words, brag
a little bit.

I'm holding my breath when I tell you to brag. If there's a fault with
discussion sections, it is when writers grossly overstate the
significance of their research. There is no shame in conducting and
reporting a ``weak'' research study. It only becomes a sin if you
pretend that a weak study is more definitive than it deserves to be.

But you're not one of these types. The writers who overstate things
never get stuck. You're stuck because you're too tentative. Adopting a
cautious ``yes, but'' tone has filled your heart with gloom and weighed
you down. It is better to start off brashly so as to get something down
on paper. You can always tone it down later.

\section{Step 3: Advocate changes (or support the status
quo)}\label{step-3-advocate-changes-or-support-the-status-quo}

The discussion section is also your chance to be a little bit ``bossy.''
If your research supports the need for changes in clinical practice,
tell us what you think those changes should be. If it supports a change
in regulations or laws, tell us that also. Tell us the future research
directions that your current findings might suggest.

\section{Step 4: Suggest areas for further
research.}\label{step-4-suggest-areas-for-further-research.}

Your study was not the last word in this research area. Maybe not, as
you will find out in the next section. But if it is indeed not the last
word, you should explain what comes next. Write down some suggestions
about what you'd like to see done. It doesn't have to be done by you,
but it needs to be done by somebody.

This takes your research paper full circle. You started out in your
literature review with the past, talked in the present about your own
work in the results section and to some extent in this discussion
section as well. The last part of the discussion section, though, is
about the future. Don't hold back your best ideas because you want to
reserve those ideas for you and you alone.

Back in Chapter 1, I reminded you how to get your research idea. Maybe
you had one already, and maybe you found it somewhere else. Maybe you
found it, though, in the discussion section of one of the papers in your
literature review. Even if you didn't those papers in your literature
review helped shape your research. So here's your chance to pay it
forward. Let someone else benefit from the wisdom that you have
accumulated because much of that accumulated ion was from those who came
before you.

\section{The fly in the ointment: When should research
end?}\label{the-fly-in-the-ointment-when-should-research-end}

\section{Bibliography}\label{bibliography-20}

HÃ¶fler M, Venz J, Trautmann S et al.~Writing a discussion section: how
to integrate substantive and statistical expertise. BMC Med Res Methodol
18, 34 (2018). DOI:
\href{https://doi.org/10.1186/s12874-018-0490-1}{10.1186/s12874-018-0490-1}

Simon SD. How to Write a Discussion Section. The Monthly Mean
newsletter, July/August 2012. Available in
\href{http://www.pmean.com/news/201207.html\#1}{html format}

\bookmarksetup{startatroot}

\chapter{Summary}\label{summary}

In summary, this book has no content whatsoever.

\bookmarksetup{startatroot}

\chapter*{References}\label{references}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\phantomsection\label{refs}

I'm thinking that maybe it makes more sense to put a bibliography at the
end of each chapter, but I haven't decided for sure just yet.




\end{document}
